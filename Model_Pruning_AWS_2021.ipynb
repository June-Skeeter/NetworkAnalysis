{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimze and a Dense Neural Network for gap filling and feature identification\n",
    "\n",
    "** With a few tweaks to RepRunner, an LSTM can be run instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "\n",
    "## Personal Modules\n",
    "import ReadStandardTimeFill as RSTF\n",
    "import importlib\n",
    "import DenseNet as Dense\n",
    "import MiscFuncs as MF\n",
    "importlib.reload(Dense)\n",
    "importlib.reload(RSTF)\n",
    "importlib.reload(MF)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "from scipy.stats import norm\n",
    "from matplotlib import cm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from ipywidgets import FloatProgress, HTML\n",
    "from IPython.display import display, clear_output\n",
    "import os  \n",
    "import shutil\n",
    "from keras import backend as K\n",
    "try:pool.close()\n",
    "except:pass\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "def RecWrite(AllRes,Path):\n",
    "    for f in AllRes.keys():\n",
    "        try:\n",
    "            os.mkdir(Path)\n",
    "        except:\n",
    "            pass\n",
    "        for t in AllRes[f].keys():\n",
    "            if t != 'Results' and t != 'Records' and t!= 'Removed':\n",
    "                for p in AllRes[f][t].keys():\n",
    "                    if t == 'X':\n",
    "                        np.save(Path+f+'_'+t+'_'+str(p)+'.npy',AllRes[f][t][p][0])\n",
    "                        \n",
    "                    else:\n",
    "                        for p2 in AllRes[f][t][p].keys():\n",
    "                            print(f,t,p,p2)\n",
    "                            np.save(Path+f+'_'+t+'_'+str(p)+'_'+str(p2)+'.npy',AllRes[f][t][p][p2])\n",
    "        AllRes[f]['Records'].to_csv(Path+f+'_Runs.csv')\n",
    "        AllRes[f]['Results'].to_csv(Path+f+'_Results.csv')\n",
    "        \n",
    "def RecRead(Path,Vars=['fco2','fch4','ER']):\n",
    "    AllRes={}\n",
    "    for f in Vars:\n",
    "        try:\n",
    "            AllRes[f]={}\n",
    "            AllRes[f]['Records']=pd.read_csv(Path+f+'_Runs.csv',index_col=0)\n",
    "            AllRes[f]['Results']=pd.read_csv(Path+f+'_Results.csv',index_col=0)\n",
    "            AllRes[f]['Derivatives']={}\n",
    "            AllRes[f]['SSQ'] ={}\n",
    "            AllRes[f]['X'] = {}\n",
    "            AllRes[f]['Yhat'] = {}\n",
    "            AllRes[f]['Ytrue'] = {}\n",
    "            AllRes[f]['Outputs'] = {}\n",
    "        except:\n",
    "            pass\n",
    "    return(AllRes)\n",
    "# print())\n",
    "\n",
    "def Test(params,X,y,YScaled,XScaled,pool):\n",
    "    return(np.random.rand(params['K']))\n",
    "\n",
    "def Stats(mse,rmse,se,r2,j,params,i=0):\n",
    "    df = pd.DataFrame(index = [str(j)+'_'+str(i)],#params['N'])],\n",
    "          data={'Model':[params['Model']],'Size':j,'Nodes':params['N']\n",
    "                ,'MSE':[mse],'RMSE':[rmse],'SE':[se],'r2':[r2],\n",
    "                'Performance':0,'K':[params['K']]})\n",
    "    return(df)\n",
    "\n",
    "def t(p,n):\n",
    "    alpha = 1-p\n",
    "    df = n-1\n",
    "    return(stats.t.ppf(alpha,df))\n",
    "\n",
    "def Display (tar,prog1=None,prog2=None,MdLs=None,MdL=None):\n",
    "    clear_output()\n",
    "    display(tar)\n",
    "    if prog1!=None:\n",
    "        display(prog1)\n",
    "    if prog2!=None:\n",
    "        display(prog2)\n",
    "    if MdLs!=None:\n",
    "        display(MdLs)\n",
    "    if MdL!=None:\n",
    "        display(MdL)\n",
    "tar = HTML(\n",
    "            value=\" \",\n",
    "            placeholder='Target: ',\n",
    "            description='Target: ',\n",
    "        )\n",
    "kwt = HTML(\n",
    "        value=str(0),\n",
    "        placeholder='Quit Score: ',\n",
    "        description='Quit Score: ',\n",
    "        )\n",
    "\n",
    "cwd = os.getcwd()\n",
    "alpha = .05\n",
    "pd.set_option('max_colwidth',200)\n",
    "\n",
    "Path = 'C:\\\\Users\\\\wesle\\\\NetworkAnalysis\\\\FishIsland/'  \n",
    "Site='FishIsland'\n",
    "try:\n",
    "    os.mkdir(Path+'/')\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlation between inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                AirTemp_Avg  Net_SW_Wm2_Avg  Net_LW_Wm2_Avg  Daytime   DSSM  \\\n",
      "co2_flux             -0.377          -0.777           0.571    0.035  0.191   \n",
      "Net_LW_Wm2_Avg       -0.484          -0.710           1.000   -0.275 -0.192   \n",
      "WindSpd               0.103           0.097          -0.134   -0.008 -0.034   \n",
      "DSSM                  0.609           0.199          -0.192    0.222  1.000   \n",
      "Daytime               0.466           0.306          -0.275    1.000  0.222   \n",
      "NDVI                  0.672           0.336          -0.282    0.280  0.751   \n",
      "AirTemp_Avg           1.000           0.528          -0.484    0.466  0.609   \n",
      "ch4_flux              0.336           0.690          -0.543    0.262 -0.454   \n",
      "Net_SW_Wm2_Avg        0.528           1.000          -0.710    0.306  0.199   \n",
      "\n",
      "                 NDVI  WindSpd  ch4_flux  co2_flux  \n",
      "co2_flux        0.012   -0.102    -0.630     1.000  \n",
      "Net_LW_Wm2_Avg -0.282   -0.134    -0.543     0.571  \n",
      "WindSpd        -0.025    1.000     0.255    -0.102  \n",
      "DSSM            0.751   -0.034    -0.454     0.191  \n",
      "Daytime         0.280   -0.008     0.262     0.035  \n",
      "NDVI            1.000   -0.025     0.005     0.012  \n",
      "AirTemp_Avg     0.672    0.103     0.336    -0.377  \n",
      "ch4_flux        0.005    0.255     1.000    -0.630  \n",
      "Net_SW_Wm2_Avg  0.336    0.097     0.690    -0.777  \n",
      "AirTemp_Avg       1.0\n",
      "Net_SW_Wm2_Avg    1.0\n",
      "Net_LW_Wm2_Avg    1.0\n",
      "SoilMoist(4)      1.0\n",
      "Daytime           1.0\n",
      "DSSM              1.0\n",
      "NDVI              1.0\n",
      "WindSpd           1.0\n",
      "dtype: float64\n",
      "                Net_SW_Wm2_Avg  Net_LW_Wm2_Avg     Angle\n",
      "Net_SW_Wm2_Avg        1.000000       -0.710335  0.256889\n",
      "Net_LW_Wm2_Avg       -0.710335        1.000000 -0.259005\n",
      "Angle                 0.256889       -0.259005  1.000000\n"
     ]
    }
   ],
   "source": [
    "Full_Input = {'AirTemp_Avg':'Ta',\n",
    "              'Net_SW_Wm2_Avg':'Radiation', \n",
    "              'Net_LW_Wm2_Avg':'Radiation',\n",
    "#               'SoilMoist(4)':'Soil',\n",
    "              'Daytime':'Daytime',\n",
    "#               'Angle':'Sun Position',\n",
    "              'DSSM':'Seasonal',\n",
    "              'NDVI':'NDVI',\n",
    "              'WindSpd':'U'}\n",
    "MP = True\n",
    "if MP == True:\n",
    "    processes = 3\n",
    "else:\n",
    "    processes = 1\n",
    "Scope = 'Full'\n",
    "# Scope = 'Test'\n",
    "Runs = 0\n",
    "Threshold = 0.025    \n",
    "params = Dense.Params(Path,Scope,None,MP=MP)\n",
    "L = list(Full_Input.keys())\n",
    "RST = RSTF.ReadStandardTimeFill(params,'AWS_FI.csv')\n",
    "L.append('ch4_flux')\n",
    "L.append('co2_flux')\n",
    "Corr = RST.Master[L].corr()\n",
    "print(Corr.sort_values(by='Net_SW_Wm2_Avg').round(3))\n",
    "np.round((RST.Master[['fco2','fch4']].count())/30)\n",
    "RST.Master.columns.values\n",
    "\n",
    "print(RST.Master[['AirTemp_Avg','Net_SW_Wm2_Avg','Net_LW_Wm2_Avg','SoilMoist(4)',\n",
    "          'Daytime','DSSM','NDVI','WindSpd']].count()/RST.Master['datetime'].count())\n",
    "# plt.figure()\n",
    "RST.Master['RN'] = RST.Master[['Net_SW_Wm2_Avg','Net_LW_Wm2_Avg']].sum(axis=1)\n",
    "print(RST.Master[['Net_SW_Wm2_Avg','Net_LW_Wm2_Avg','Angle']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d511ad263a464cf88475ddbe95370ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='fch4', description='Target: ', placeholder='Target: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11bb85fe9174d768b318a200443cad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, description='Bootstrapping:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0935ebfe3bb54098bbd855ff5bdfc561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"N = 7:  ['AirTemp_Avg', 'Net_SW_Wm2_Avg', 'Net_LW_Wm2_Avg', 'Daytime', 'DSSM', 'NDVI', 'WindSpd']\"â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "Inputs!:  ['AirTemp_Avg', 'Net_SW_Wm2_Avg', 'Net_LW_Wm2_Avg', 'Daytime', 'DSSM', 'NDVI', 'WindSpd']\n",
      "Total Runtime:  353.29343461990356\n",
      "Training Time:  0.015002012252807617\n",
      "N:  43\n",
      "C:\\Users\\wesle\\NetworkAnalysis\\FishIsland/ C:\\Users\\wesle\\NetworkAnalysis\\FishIsland//fch4/7_43/\n",
      "fch4 ['AirTemp_Avg', 'Net_SW_Wm2_Avg', 'Net_LW_Wm2_Avg', 'Daytime', 'DSSM', 'NDVI', 'WindSpd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fco2 Derivatives 7 75\n",
      "fco2 SSQ 7 75\n",
      "fco2 Yhat 7 75\n",
      "fco2 Ytrue 7 75\n",
      "fco2 Outputs 7 75\n",
      "fch4 Derivatives 7 43\n",
      "fch4 SSQ 7 43\n",
      "fch4 Yhat 7 43\n",
      "fch4 Ytrue 7 43\n",
      "fch4 Outputs 7 43\n"
     ]
    }
   ],
   "source": [
    "Time = time.time()\n",
    "AllRes={}\n",
    "if __name__ == '__main__':\n",
    "    for target in ['fco2','fch4']:\n",
    "#     for target in ['fco2']:\n",
    "        params['target']=target\n",
    "        Thresh = Threshold*1\n",
    "        try:\n",
    "            shutil.rmtree(params['Dpath']+'/'+target+'/')\n",
    "        except: pass\n",
    "        try: \n",
    "            os.mkdir(params['Dpath']+'/'+target+'/')\n",
    "        except: pass\n",
    "        AllRes[target]={}\n",
    "        AllRes[target]['Derivatives'] = {}\n",
    "        AllRes[target]['SSQ'] ={}\n",
    "        AllRes[target]['X'] = {}\n",
    "        AllRes[target]['Yhat'] = {}\n",
    "        AllRes[target]['Ytrue'] = {}\n",
    "        AllRes[target]['Outputs'] = {}\n",
    "        Rm = []\n",
    "        Input = list(Full_Input.keys())\n",
    "        start = len(Input)\n",
    "        IpKey=np.arange(0,start)\n",
    "        IpDict={'Factors':Input.copy(),'Key':IpKey}\n",
    "        tar.value=target\n",
    "        prog2 = FloatProgress(min=0, max=100,description='Bootstrapping:')\n",
    "        MdL = HTML(value=\" \",placeholder='Testing: ',description='Testing: ')\n",
    "        Continue = True\n",
    "        run = 1\n",
    "        Kill = Runs\n",
    "        while len(Input)>0 and run == 1:\n",
    "            params = Dense.Params(Path,Scope,target,MP=MP)\n",
    "            j = len(Input)\n",
    "            AllRes[target]['Derivatives'][j] = {}\n",
    "            AllRes[target]['SSQ'][j] ={}\n",
    "            AllRes[target]['Yhat'][j] = {}\n",
    "            AllRes[target]['Ytrue'][j] = {}\n",
    "            AllRes[target]['Outputs'][j] = {}\n",
    "            Time2 = time.time()\n",
    "            params['Inputs'] = Input\n",
    "            MdL.value='N = '+str(j)+':  '+str(params['Inputs'])\n",
    "            Display (tar,prog2=prog2,MdL=MdL)\n",
    "            print(run,Kill)\n",
    "            print('Inputs!: ', params['Inputs'])\n",
    "            print('Total Runtime: ',time.time()-Time)\n",
    "            print('Training Time: ', time.time()-Time2)\n",
    "            params['Model'] = '+'.join(params['Inputs'])\n",
    "            RST = RSTF.ReadStandardTimeFill(params,'AWS_FI.csv')#,resample='3H')\n",
    "            if target == 'ER':\n",
    "                RST.Master = RST.Master.loc[RST.Master['co2_flux']>0]\n",
    "            params['N'] = int(np.round(RST.Master[target].count()*(1-params['validation_split'])/30))\n",
    "            print('N: ',params['N'])\n",
    "            params['Sname'] = 'Y_'\n",
    "            params['Spath'] = params['Dpath']+'/'+target+'/'+str(j)+'_'+str(params['N'])+'/'\n",
    "            print(params['Dpath'],params['Spath'])\n",
    "            try:\n",
    "                os.mkdir(params['Spath'])\n",
    "            except:\n",
    "                pass\n",
    "            print(params['target'],params['Inputs'])\n",
    "            RST.Scale(params['target'],params['Inputs']) \n",
    "            y = RST.y*1.0\n",
    "            X = RST.X*1.0\n",
    "            params['Memory'] = (math.floor(100/params['proc'])- 5/params['proc']) * .01\n",
    "            Y_hat=[]\n",
    "            y_true=[]\n",
    "            X_true=[]\n",
    "            index=[]\n",
    "            ones=[]\n",
    "            prog2.value=0\n",
    "            Avs = []\n",
    "            Derivatives = []\n",
    "            Outputs=[]\n",
    "            if MP == False:\n",
    "                for k in range(params['K']):\n",
    "                    results = Dense.Bootstrap(k,params=params,X=X,y=y)\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0].reshape(-1,1)))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1].reshape(-1,1)))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    ones.append(results[3])\n",
    "                    prog2.value=(k+1)/params['K']*100\n",
    "                    Avs.append(results[4])\n",
    "                    Derivatives.append(results[5])\n",
    "                    Outputs = results[6]\n",
    "            else:\n",
    "                pool = Pool(processes=processes,maxtasksperchild=75)\n",
    "                for k,results in enumerate(pool.imap_unordered(partial(Dense.Bootstrap,params=params,X=X,y=y)\n",
    "                                                               ,range(params['K']))):\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    ones.append(results[3])\n",
    "                    prog2.value=(k+1)/params['K']*100\n",
    "                    Avs.append(results[4])\n",
    "                    Derivatives.append(results[5])\n",
    "                    Outputs.append(results[6])\n",
    "                pool.close()\n",
    "            Y_hat = np.squeeze(np.asanyarray(Y_hat))\n",
    "            y_true = np.squeeze(np.asanyarray(y_true))\n",
    "            X_true = np.asanyarray(X_true)\n",
    "            ones = np.asanyarray(ones)\n",
    "            params['Memory'] = .95\n",
    "            results = Dense.Sort_outputs(0,params=params,Y_hat=Y_hat,y_true=y_true,X_true=X_true,ones=ones)\n",
    "            mse,rmse,se,r2,Y_Val,Y_hat_Val = results\n",
    "            Level = Stats(mse,rmse,se,r2,j,params,i=params['N'])\n",
    "            Level.to_csv('Temp.csv')\n",
    "            Level['Thresh'] = Level['MSE']+Level['SE']\n",
    "            Level['Remove'] = 'N/A'\n",
    "            Min = Level.loc[Level['MSE']==Level['MSE'].min()]\n",
    "            if Kill == Runs:\n",
    "                Records = Level\n",
    "            else:\n",
    "                Records = Records.append(Level)\n",
    "            Av = np.array(Avs).mean(axis=0)\n",
    "            Drv = np.array(Derivatives)\n",
    "            Range = Drv.mean(axis=0).max(axis=1)-Drv.mean(axis=0).min(axis=1)\n",
    "            SE = np.array(Avs).std(axis=0)**.5/(params['K']**.5)\n",
    "            Key = str(j)+'_'+ str(params['N'])\n",
    "            if Kill<Runs:\n",
    "                IpDict['RC_Sum: '+Key]=np.zeros(Results.shape[0])\n",
    "                IpDict['RC: '+Key]=np.zeros(Results.shape[0])\n",
    "                IpDict['RG: '+Key]=np.zeros(Results.shape[0])\n",
    "                IpDict['SE: '+Key]=np.zeros(Results.shape[0])\n",
    "                IpDict['CS: '+Key]=np.zeros(Results.shape[0])\n",
    "            Results = pd.DataFrame(data=IpDict)\n",
    "            for I,A,S,R in zip(Input,Av,SE,Range):\n",
    "                Results.loc[Results['Factors']==I,'RC: '+Key]=A\n",
    "                Results.loc[Results['Factors']==I,'RG: '+Key]=R\n",
    "                Results.loc[Results['Factors']==I,'SE: '+Key]=S\n",
    "            Results['RC_Sum: '+Key]=Results['RC: '+Key]/Results['RC: '+Key].sum()\n",
    "            IpDict['RC_Sum: '+Key]=Results['RC_Sum: '+Key].values\n",
    "            IpDict['RC: '+Key]=Results['RC: '+Key].values\n",
    "            IpDict['RG: '+Key]=Results['RG: '+Key].values\n",
    "            IpDict['SE: '+Key]=Results['SE: '+Key].values\n",
    "            Results = Results.sort_values('RC: '+Key)\n",
    "            Resluts = Results.reset_index()\n",
    "            Results['CS: '+Key]=Results['RC_Sum: '+Key].sort_values(ascending=False).cumsum().sort_values(ascending=False)\n",
    "            Results = Results.sort_values('Key')\n",
    "            IpDict['CS: '+Key]=Results['CS: '+Key].values\n",
    "            Min = Records.loc[Records['MSE']==Records['MSE'].min()]\n",
    "            ## Saving\n",
    "            AllRes[target]['Records'] = Records\n",
    "            AllRes[target]['Results'] = Results\n",
    "            AllRes[target]['Derivatives'][j][params['N']] = Drv\n",
    "            AllRes[target]['SSQ'][j][params['N']] = Avs\n",
    "            AllRes[target]['X'][j] = X_true\n",
    "            AllRes[target]['Outputs'][j][params['N']] = Outputs\n",
    "            AllRes[target]['Yhat'][j][params['N']] = Y_hat_Val\n",
    "            AllRes[target]['Ytrue'][j][params['N']] = Y_Val \n",
    "            Vee = 'RC_Sum: '+Key\n",
    "            # Remove Thresh\n",
    "            NewInput = Results.loc[Results[Vee]>Thresh,'Factors'].values\n",
    "            # Remove Last\n",
    "#             NewInput = Results.loc[Results[Vee]>Results[Vee].min(),'Factors'].values\n",
    "            if run <= 1 and Kill > 0:\n",
    "                if len(NewInput) == len(Input):\n",
    "                    run = 0\n",
    "                elif len(NewInput)==0:\n",
    "                    run = 0\n",
    "                else:\n",
    "                    Input = NewInput\n",
    "                Kill -= 1\n",
    "            else:\n",
    "                run = 0\n",
    "\n",
    "RecWrite(AllRes,Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['7_75'], dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [Model, Size, Nodes, MSE, RMSE, SE, r2, Performance, K, Thresh, Remove]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-dd2727b48a15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRecords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mNodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mDerivatives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_Derivatives_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mBest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "Model_Index = None\n",
    "F = 'fco2'\n",
    "Model_Index = '8_75'\n",
    "# F = 'fch4'\n",
    "# Model_Index = '8_43'\n",
    "\n",
    "Results = AllRes[F]['Results'].copy()\n",
    "Records = AllRes[F]['Records'].copy()\n",
    "if Model_Index == None:\n",
    "    Best = Records.loc[Records['Size']==Records['Size'].min()]\n",
    "else:\n",
    "    Best = Records.loc[Records.index==Model_Index]    \n",
    "print(Records.index)\n",
    "print(Best)\n",
    "Size = Best.Size.values[0]\n",
    "Nodes = Best.Nodes.values[0]\n",
    "Derivatives = np.load(Path+F+'_Derivatives_'+Best.index.values[0]+'.npy')\n",
    "Mean = Derivatives.mean(axis=0)\n",
    "X = np.load(Path+F+'_X_'+str(Size)+'.npy')\n",
    "                 \n",
    "Results['Group']=''\n",
    "A=[]\n",
    "for val in Results.Factors.values:\n",
    "    try:Resluts.loc[Results['Factors']==val,'Group']=Classes[val]\n",
    "    except:pass\n",
    "    A.append(Full_Input[val])\n",
    "Results['Group']=A\n",
    "print(Results.groupby('Group').sum()['RC_Sum: '+Best.index.values[0]].sort_values())\n",
    "\n",
    "RMSE=[]\n",
    "plt.figure()\n",
    "y = np.load(Path+F+'_Yhat_'+Best.index.values[0]+'.npy')\n",
    "x = np.load(Path+F+'_Ytrue_'+Best.index.values[0]+'.npy')\n",
    "for i in range(y.shape[0]):\n",
    "    df = pd.DataFrame(data={'target':y[i],'y':x[i]}).dropna()\n",
    "    rmse = metrics.mean_squared_error(df['y'],df['target'])**.5\n",
    "    RMSE.append(rmse)\n",
    "plt.legend()\n",
    "slope,intercept,r,p,SE = stats.linregress(df['y'],df['target'])\n",
    "df = pd.DataFrame(data={'target':np.nanmean(y,axis=0),'y':np.nanmean(x,axis=0)}).dropna()\n",
    "plt.scatter(df['y'],df['target'],s=2,label='r2 '+str(np.round(r**2,3)))\n",
    "plt.xlim(df['y'].min(),df['y'].max())\n",
    "plt.ylim(df['y'].min(),df['y'].max())\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "a = 'RC: '+Best.index.values[0]\n",
    "ase = 'SE: '+Best.index.values[0]\n",
    "try:\n",
    "    Results = Results.loc[Results[a]>0].sort_values(a,ascending=True).reset_index()\n",
    "except:\n",
    "    pass\n",
    "fig,ax=plt.subplots(figsize=(6.5,7))\n",
    "ax.barh(Results.index,Results['RC_Sum: '+Best.index.values[0]],\n",
    "         height=.4,color='g',edgecolor='k')\n",
    "# ax2=ax.twiny()\n",
    "# ax2.plot(Results['CS: '+Best.index.values[0]],Results.index,color='k')\n",
    "ax.set_yticks(Results.index)\n",
    "ax.set_yticklabels(Results['Factors'].values)\n",
    "ax.set_xlabel('Relative Feature Importance %')\n",
    "ax.set_title('Partial Derivative Method: '+F)\n",
    "ax.grid()\n",
    "# ax.set_xlim(0,1)\n",
    "# ax2.set_xlim(0,1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('PAD_'+F+'_PrunedFactors.png')\n",
    "# print(Results[['Factors',a,'RG: 21_74']].sort_values(by=a,ascending=True))\n",
    "# print(Results['RG: 21_74'].median())\n",
    "\n",
    "print(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
