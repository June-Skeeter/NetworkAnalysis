{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimze and a Dense Neural Network for gap filling and feature identification\n",
    "\n",
    "** With a few tweaks to RepRunner, an LSTM can be run instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "# from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Personal Modules\n",
    "import ReadStandardTimeFill as RSTF\n",
    "import importlib\n",
    "import DenseNet as Dense\n",
    "import MiscFuncs as MF\n",
    "importlib.reload(Dense)\n",
    "importlib.reload(RSTF)\n",
    "importlib.reload(MF)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.externals import joblib\n",
    "from matplotlib import cm\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import os  \n",
    "import shutil\n",
    "from keras import backend as K\n",
    "try:pool.close()\n",
    "except:pass\n",
    "\n",
    "\n",
    "def Test(params,X,y,YScaled,XScaled,pool):\n",
    "    return(np.random.rand(params['K']))\n",
    "\n",
    "\n",
    "def ModSelect(Scope,Site):\n",
    "    if Site == 'Illisarvik':\n",
    "        if Scope == 'Full':\n",
    "            Model = ['wind_speed','air_pressure','PPFD_Avg','AirTC_Avg','VPD',\n",
    "                    'Temp','VWC','Sedge','Shrub','Grass','Sparse','Out_of_Basin']\n",
    "        if Scope == 'Test':\n",
    "            Model = ['PPFD_Avg','Sedge','VPD','wind_speed']\n",
    "    if Site == 'FishIsland':\n",
    "        BaseFactors = []\n",
    "        if Scope == 'Full':\n",
    "            Model = ['H','Wind Spd','air pressure','Ta','Rn','PPFD','Rain','Water Table',\n",
    "            'Ts 2.5 cm','Ts 15 cm','VWC','Active Layer','24H Rain','Wtr Tbl Trnd']\n",
    "        if Scope == 'Test':\n",
    "            Model = ['H','Water Table','Wind Spd','Active Layer']\n",
    "    return(Model)\n",
    "\n",
    "def Combos(Model,L,factor=None):\n",
    "    Models=[]\n",
    "    for c in combinations(Model,L):\n",
    "        c = list(c)\n",
    "        if factor is None:\n",
    "            Models.append(c)\n",
    "        else:\n",
    "            for f in factor:\n",
    "                f = f.split('+')\n",
    "                if set(f).issubset(set(c)) and c not in Models:\n",
    "                    Models.append(c)\n",
    "                    \n",
    "    print('Models: ',Models)\n",
    "    return(Models)\n",
    "\n",
    "def Stats(mse,se,j,i,params):\n",
    "    df = pd.DataFrame(index = [str(j)+'_'+str(i)],\n",
    "                      data={'Model':[params['Model']],\n",
    "                            'MSE':[mse],\n",
    "                            'Size':j,\n",
    "                            'Number':i,\n",
    "                            'SE':[se],\n",
    "                            'Performance':0})\n",
    "    return(df)\n",
    "\n",
    "def t(p,n):\n",
    "    alpha = 1-p\n",
    "    df = n-1\n",
    "    return(stats.t.ppf(alpha,df))\n",
    "\n",
    "\n",
    "FirstRun = True\n",
    "# FirstRun = False\n",
    "\n",
    "MP=True\n",
    "# MP=False\n",
    "processes=3\n",
    "Scope = 'Full'\n",
    "cwd = os.getcwd()\n",
    "# for Site in ['Illisarvik','FishIsland']:\n",
    "Site='Illisarvik'\n",
    "target='fch4'\n",
    "T= 1#t(0.05,params['K'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9a0361e4454268838b7512939fd603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models:  [['wind_speed'], ['air_pressure'], ['PPFD_Avg'], ['AirTC_Avg'], ['VPD'], ['Temp'], ['VWC'], ['Sedge'], ['Shrub'], ['Grass'], ['Sparse'], ['Out_of_Basin']]\n",
      "Testing:  ['wind_speed']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-234:\n",
      "Process ForkPoolWorker-235:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-236:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 135, in Bootstrap\n",
      "    Y_hat=Train_DNN(params,X_train,y_train,X,y)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 91, in Train_DNN\n",
      "    validation_split=params['validation_split']) # Validation Fracton\n",
      "  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 135, in Bootstrap\n",
      "    Y_hat=Train_DNN(params,X_train,y_train,X,y)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 1183, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 867, in fit\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 2270, in __call__\n",
      "    session = get_session()\n",
      "  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 135, in Bootstrap\n",
      "    Y_hat=Train_DNN(params,X_train,y_train,X,y)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 1598, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 91, in Train_DNN\n",
      "    validation_split=params['validation_split']) # Validation Fracton\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 1598, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 867, in fit\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 1183, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 167, in get_session\n",
      "    _initialize_variables()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 2273, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 336, in _initialize_variables\n",
      "    if not hasattr(v, '_keras_initialized') or not v._keras_initialized:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 91, in Train_DNN\n",
      "    validation_split=params['validation_split']) # Validation Fracton\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn\n",
      "    status, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 867, in fit\n",
      "    initial_epoch=initial_epoch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9547ecb4c09a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxtasksperchild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mY_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYScaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 1598, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 1183, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 2273, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn\n",
      "    status, run_metadata)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' and FirstRun == True:\n",
    "    XVarriables=ModSelect(Scope,Site)\n",
    "    prog = FloatProgress(min=0, max=len(XVarriables)+1,description='Running:') # instantiate the bar\n",
    "    prog2 = FloatProgress(min=0, max=100,description='Running:') # instantiate the bar\n",
    "    display(prog) # display the bar\n",
    "    try:shutil.rmtree(cwd+'/'+Site+'/'+target+'/')\n",
    "    except:pass\n",
    "    os.mkdir(cwd+'/'+Site+'/'+target+'/')\n",
    "    for j in range(1,len(XVarriables)+1):\n",
    "        if j == 1: Inputs = (Combos(XVarriables,j))\n",
    "        else: Inputs = (Combos(XVarriables,j,Factors))\n",
    "        i = 0\n",
    "        for Input in Inputs:\n",
    "            params = Dense.Params(Scope,target,MP)\n",
    "            params['Dpath'] = cwd+'/'+Site+'/'\n",
    "            params['Spath'] = params['Dpath']+'/'+target+'/'+str(j)+'_'+str(i)+'/'\n",
    "            try:os.mkdir(params['Spath'])\n",
    "            except:pass\n",
    "            params['Sname'] = 'Y_'\n",
    "            params['Inputs'] = Input\n",
    "            params['Model'] = '+'.join(params['Inputs'])\n",
    "            RST = RSTF.ReadStandardTimeFill(params,'ECData.csv')#,resample='2H')\n",
    "            RST.Scale(params['target'],params['Inputs']) \n",
    "            y = RST.y*1.0\n",
    "            X = RST.X*1.0\n",
    "            params['N']=int(y.shape[0]/30)\n",
    "            params['Memory'] = (math.floor(100/params['proc'])- 5/params['proc']) * .01\n",
    "            Y_hat=[]\n",
    "            y_true=[]\n",
    "            X_true=[]\n",
    "            index=[]\n",
    "            ones=[]\n",
    "            print('Testing: ',params['Inputs'])\n",
    "            p\n",
    "            if MP == False:\n",
    "                for k in range(params['K']):\n",
    "                    results = Dense.Bootstrap(k,params,X,y)\n",
    "#                     d = input('dook')                    plt.figure()\n",
    "#                     plt.scatter(RST.YScaled.inverse_transform(results[0]),\n",
    "#                                RST.YScaled.inverse_transform(results[1]))\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    ones.append(results[3])\n",
    "                    prog2.value=(k+1)/params['k']*100\n",
    "#                     ones.append(results[4])\n",
    "            else:\n",
    "                pool = Pool(processes=processes,maxtasksperchild=75)\n",
    "                for k,results in enumerate(pool.imap(partial(Dense.Bootstrap,params=params,X=X,y=y),range(params['K']))):\n",
    "\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    ones.append(results[3])\n",
    "                    prog2.value=(k+1)/params['k']*100\n",
    "#                     ones.append(results[4])\n",
    "                pool.close()\n",
    "            Y_hat = np.squeeze(np.asanyarray(Y_hat))\n",
    "            y_true = np.squeeze(np.asanyarray(y_true))\n",
    "            X_true = np.asanyarray(X_true)\n",
    "#             index = np.asanyarray(index)\n",
    "            ones = np.asanyarray(ones)\n",
    "            params['Memory'] = .95\n",
    "            if MP == False:\n",
    "                for k in range(1):\n",
    "                     mse,se = Dense.Sort_outputs(k,params,Y_hat,y_true,X_true,ones)\n",
    "            else:\n",
    "                pool = Pool(processes=1,maxtasksperchild=75)\n",
    "                for k,results in enumerate(pool.imap(partial(Dense.Sort_outputs,params=params,\n",
    "                 Y_hat=Y_hat,y_true=y_true,X_true=X_true,ones=ones),range(1))):\n",
    "                     mse,se = results\n",
    "                pool.close()\n",
    "            if i == 0:Level = Stats(mse,se,j,i,params)\n",
    "            else:Level = Level.append(Stats(mse,se,j,i,params))\n",
    "            i += 1\n",
    "            prog.value=j+i/len(Inputs)\n",
    "        Min = Level.loc[Level['MSE']==Level['MSE'].min()]\n",
    "        T= t(0.05,params['K'])\n",
    "        Factors = Level.loc[Level['MSE']<=Min['MSE'].values[0]+Min['SE'].values[0]*T,'Model'].values\n",
    "        print(Factors)\n",
    "        Level.loc[Level['MSE']<=Min['MSE'].values[0]+Min['SE'].values[0]*T,'Performance']=1\n",
    "        if j == 1:Records = Level\n",
    "        else:Records = Records.append(Level)\n",
    "\n",
    "    Records = Records.reset_index(drop=True)\n",
    "    Min = Records.loc[Records['MSE']==Records['MSE'].min()]\n",
    "    Records.loc[Records['MSE']<=Min['MSE'].values[0]+Min['SE'].values[0]*T,'Performance']=2\n",
    "    Records.loc[Records['MSE']==Min['MSE'].values[0],'Performance']=3\n",
    "    Honorable = Records.loc[Records['Performance']==1]\n",
    "    Top = Records.loc[Records['Performance']==2]\n",
    "    Best = Records.loc[Records['Performance']==3]\n",
    "    plt.figure()\n",
    "    plt.bar(Honorable.index,Honorable['MSE'],yerr=Honorable['SE'],color='blue')\n",
    "    plt.bar(Top.index,Top['MSE'],yerr=Top['SE'],color='green')\n",
    "    plt.bar(Best.index,Best['MSE'],yerr=Best['SE'],color='red')\n",
    "    Records.drop(Records.columns[Records.columns.str.contains('Unnamed',case = False)],axis = 1)\n",
    "    Records.to_csv(params['Dpath']+'/'+target+'_Runs.csv')\n",
    "    FirstRun = False\n",
    "else:    \n",
    "    print('OldRun!')\n",
    "    params = Dense.Params(Scope,target,MP)\n",
    "    params['Dpath'] = cwd+'/'+Site+'/'\n",
    "    RST = RSTF.ReadStandardTimeFill(params,'ECData.csv')#,resample='2H')\n",
    "    params = Dense.Params(Scope,target,MP)\n",
    "    params['Dpath'] = cwd+'/'+Site+'/'\n",
    "    Records = pd.read_csv(params['Dpath']+'/'+target+'_Runs.csv',delimiter = ',',header = 0)\n",
    "    Min = Records.loc[Records['MSE']==Records['MSE'].min()]\n",
    "    Records.loc[Records['MSE']<=Min['MSE'].values[0]+Min['SE'].values[0]*T,'Performance']=2\n",
    "    Records.loc[Records['MSE']==Min['MSE'].values[0],'Performance']=3\n",
    "    T= 1#t(0.05,params['K'])\n",
    "    Honorable = Records.loc[Records['Performance']==1]\n",
    "    Top = Records.loc[Records['Performance']==2]\n",
    "    Best = Records.loc[Records['Performance']==3]\n",
    "    plt.figure()\n",
    "    plt.bar(Honorable.index,Honorable['MSE'],yerr=Honorable['SE'],color='blue')\n",
    "    plt.bar(Top.index,Top['MSE'],yerr=Top['SE'],color='green')\n",
    "    plt.bar(Best.index,Best['MSE'],yerr=Best['SE'],color='red')\n",
    "    Records.to_csv(params['Dpath']+'/'+target+'_Runs.csv')\n",
    "print(Records)\n",
    "print((Records['MSE']+Records['SE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "alt_mod=[False,'PPFD_Avg+wind_speed+Sedge']\n",
    "BestMod = Best['Model'].values[0]\n",
    "Project = False\n",
    "Fill = False\n",
    "if alt_mod[0] == True:\n",
    "    Model = alt_mod[1]\n",
    "else:\n",
    "    Model = BestMod\n",
    "idx = Records['index'].loc[Records['Model']==Model].values[0]\n",
    "Model = Model.split('+')\n",
    "params['Spath']=(params['Dpath']+'/'+target+'/'+idx+'/')\n",
    "params['Inputs']=Model\n",
    "RST.Scale(params['target'],params['Inputs'],ScalePath=params['Spath'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "\n",
    "# print(Data[params['target']])\n",
    "\n",
    "for ip in params['Inputs']:\n",
    "    RST.Data[ip] = RST.Data[ip].mean()\n",
    "\n",
    "Key = 'Sedge'\n",
    "KeyRange = {'min':0,'max':1}\n",
    "RST.Data[Key] = np.linspace(KeyRange['min'],KeyRange['max'],RST.Data[Key].shape[0])\n",
    "RST.Scale(params['target'],params['Inputs'],ScalePath=params['Spath'],Project=Project)\n",
    "    \n",
    "# print(Data[params['target']])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if Fill == True:\n",
    "        X = RST.X_fill\n",
    "    else:\n",
    "        X = RST.X\n",
    "    params['Sname']='Y_'\n",
    "    Y_fill = []\n",
    "    MSE = []\n",
    "#     for i in range(params['K']):\n",
    "        \n",
    "        \n",
    "        \n",
    "    if MP == False:\n",
    "        for k in range(params['K']):\n",
    "            Y = Dense.Load_Model(k,X,params)\n",
    "            Y = RST.YScaled.inverse_transform(Y)\n",
    "            if Fill == False:\n",
    "                mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "                MSE.append(mse)\n",
    "            Y_fill.append(Y)\n",
    "    else:\n",
    "        pool = Pool(processes=1,maxtasksperchild=75)\n",
    "        for k,results in enumerate(pool.imap(partial(Dense.Load_Model,X=X,params=params),range(params['K']))):\n",
    "            Y = results\n",
    "            Yold = Y+0\n",
    "            Y = RST.YScaled.inverse_transform(Y)\n",
    "#             plt.figure()\n",
    "#             plt.scatter(Y,Yold)\n",
    "#             plt.xlabel('Sca;e')\n",
    "#             print(RST.YScaled)\n",
    "            if Fill == False:\n",
    "                mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "                MSE.append(mse)\n",
    "            Y_fill.append(Y)                       \n",
    "        pool.close()\n",
    "#         params['iteration']=i\n",
    "\n",
    "#         Y = Dense.Load_Model(i,X,params)\n",
    "#         Model = Dense.Load_Weights(Empty_Mod,params) \n",
    "#         Y = RST.YScaled.inverse_transform(Y)#Model.predict(X).reshape(-1,1))\n",
    "#         if Fill == False:\n",
    "#             mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "#             MSE.append(mse)\n",
    "#         Y_fill.append(Y)\n",
    "    Y_fill = np.asanyarray(Y_fill).mean(axis=-1)\n",
    "    Y_fill_bar = Y_fill.mean(axis=0)\n",
    "    if Fill == False:\n",
    "        MSE = np.asanyarray(MSE)\n",
    "        CI = stats.t.ppf(1-0.025,k)*MSE.std()/(k)**.5\n",
    "        print(CI)\n",
    "\n",
    "    YStandard = joblib.load(params['Spath']+\"YVar_scaler.save\") \n",
    "    params['Sname']='Var'\n",
    "#     params['iteration']=1\n",
    "    params['Loss']='Boot_Loss'\n",
    "#     YVar = Dense.Load_Model(1,X,params)\n",
    "#     Model = Dense.Load_Weights(Empty_Mod,params)        \n",
    "    if MP == False:\n",
    "        for k in range(1,2):\n",
    "            YVar = Dense.Load_Model(k,X,params)\n",
    "            YVar = RST.YScaled.inverse_transform(YVar)\n",
    "#             if Fill == False:\n",
    "#                 mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "#                 MSE.append(mse)\n",
    "#             Y_fill.append(Y)\n",
    "    else:\n",
    "        pool = Pool(processes=1,maxtasksperchild=75)\n",
    "        for k,results in enumerate(pool.imap(partial(Dense.Load_Model,X=X,params=params),range(1,2))):\n",
    "            YVar = results\n",
    "            YVar = RST.YScaled.inverse_transform(YVar)\n",
    "#             if Fill == False:\n",
    "#                 mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "#                 MSE.append(mse)\n",
    "#             Y_fill.append(Y)                       \n",
    "        pool.close()\n",
    "#     YVar=YStandard.inverse_transform(YVar)#Model.predict(X).reshape(-1,1))\n",
    "    X_back = np.squeeze(RST.XScaled.inverse_transform(X))\n",
    "\n",
    "\n",
    "Data = pd.DataFrame(data=X_back,columns=params['Inputs'])\n",
    "Data[target] = np.squeeze(Y_fill_bar)\n",
    "Data['True'] = RST.Ytru#.YScaled.inverse_transform(RST.y)\n",
    "Data['SE'] = 1/(params['K']-1)*((Y_fill-Y_fill_bar)**2).sum(axis=0)\n",
    "Data['Var'] = np.squeeze(YVar)\n",
    "Data['CI']=stats.t.ppf(1-0.025,params['K'])*(Data['SE'])**.5\n",
    "Data['PI']=stats.t.ppf(1-0.025,params['K'])*((Data['Var']+Data['SE'])**.5) #the accuracy of our estimate with respect to the observed output\n",
    "\n",
    "# print(Data['CI'].mean())\n",
    "print(params['Inputs'])\n",
    "print('Prediction mean: ',Data[target].mean())\n",
    "print('Target mean: ',Data['True'].mean())\n",
    "Data['Fill'] = Data['True'].fillna(Data[target])\n",
    "print('GapFilled mean: ',Data['Fill'].mean())\n",
    "\n",
    "Data.loc[np.isnan(Data['PI'])==True,'PI']=Data['CI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "Data = Data.sort_values(by=Key)\n",
    "# Data.index = Data[Key]\n",
    "\n",
    "Data = Data[np.isfinite(Data['True'])]\n",
    "\n",
    "plt.scatter(RST.Master[Key],RST.Master[target],edgecolor='black',facecolor='white')\n",
    "plt.plot(Data[Key],Data[target],\n",
    "         label= params['target']+' Model\\nr^2: '+str(np.round(metrics.r2_score(Data['True'],\n",
    "                                                                   Data[params['target']])**2,3)))\n",
    "# plt.plot(Data.index,Data['Var'],label= params['target']+\n",
    "# ' Model\\nRMSE: '+str(np.round(metrics.mean_squared_error(Data['True'],\n",
    "#                                                                    Data[params['target']])**2,3)))\n",
    "\n",
    "\n",
    "plt.fill_between(Data[Key], Data[target]-Data['PI'], \n",
    "                 Data[target]+Data['PI'],  color = 'green', alpha = 0.4, \n",
    "                 label = '95% PI')\n",
    "plt.fill_between(Data[Key], Data[target]-Data['CI'], \n",
    "                 Data[target]+Data['CI'],  color = 'red', alpha = 0.4, \n",
    "                 label = '95% CI')\n",
    "plt.legend()\n",
    "# print(RST.Master)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# plt.plot(Data[Key], Data['Var'])\n",
    "\n",
    "plt.scatter(Data[target],Data['True'])\n",
    "\n",
    "# print(Data['SE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
