{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimze and a Dense Neural Network for gap filling and feature identification\n",
    "\n",
    "** With a few tweaks to RepRunner, an LSTM can be run instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "# from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from sklearn import metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Personal Modules\n",
    "import ReadStandardTimeFill as RSTF\n",
    "import importlib\n",
    "import DenseNet as Dense\n",
    "import MiscFuncs as MF\n",
    "importlib.reload(Dense)\n",
    "importlib.reload(RSTF)\n",
    "importlib.reload(MF)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.externals import joblib\n",
    "from matplotlib import cm\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import os  \n",
    "from functools import partial\n",
    "import shutil\n",
    "from keras import backend as K\n",
    "try:pool.close()\n",
    "except:pass\n",
    "\n",
    "\n",
    "def Test(params,X,y,YScaled,XScaled,pool):\n",
    "    return(np.random.rand(params['K']))\n",
    "\n",
    "\n",
    "def ModSelect(Scope,Site):\n",
    "    if Site == 'Illisarvik':\n",
    "        if Scope == 'Full':\n",
    "            Model = ['H','wind_speed','air_pressure','PPFD_Avg','AirTC_Avg','VPD',\n",
    "                    'Temp','VWC','Sedge','Shrub','Grass','Sparse','Out_of_Basin']\n",
    "        if Scope == 'Test':\n",
    "            Model = ['PPFD_Avg','wind_speed']#,'Temp','VWC','Sedge']\n",
    "    if Site == 'FishIsland':\n",
    "        BaseFactors = []\n",
    "        if Scope == 'Full':\n",
    "            Model = ['H','Wind Spd','air pressure','Ta','Rn','PPFD','Rain','Water Table',\n",
    "            'Ts 2.5 cm','Ts 15 cm','VWC','Active Layer','24H Rain','Wtr Tbl Trnd']\n",
    "        if Scope == 'Test':\n",
    "            Model = ['H','Water Table','Wind Spd','Active Layer']\n",
    "    return(Model)\n",
    "\n",
    "def Combos(Model,L,factor=None):\n",
    "    Models=[]\n",
    "    for c in combinations(Model,L):\n",
    "        c = list(c)\n",
    "        if factor is None:\n",
    "            Models.append(c)\n",
    "        else:\n",
    "            for f in factor:\n",
    "                f = f.split('+')\n",
    "                if set(f).issubset(set(c)) and c not in Models:\n",
    "                    Models.append(c)\n",
    "                    \n",
    "    print('Models: ',Models)\n",
    "    return(Models)\n",
    "\n",
    "def Stats(mse,j,i,params):\n",
    "    df = pd.DataFrame(index = [str(j)+'_'+str(i)],\n",
    "                      data={'Model':[params['Model']],\n",
    "                            'MSE':[mse.mean()],\n",
    "                            'SE':[mse.std()/params['K']**.5],\n",
    "                            'Performance':0})\n",
    "    return(df)\n",
    "\n",
    "def t(p,n):\n",
    "    alpha = 1-p\n",
    "    df = n-1\n",
    "    return(stats.t.ppf(alpha,df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aefd995078e46e38b0eacd178765bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models:  [['PPFD_Avg'], ['wind_speed']]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(50, 1), b.shape=(1, 8), m=50, n=8, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_dense_1_input_0_0/_19, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_51 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_447_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'dense_1/MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-701261f2032c>\", line 57, in <module>\n    results = Dense.TTV_Split(k,params,X,y)\n  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 111, in TTV_Split\n    Y_hat=Train_DNN(params,X_train,y_train,X_test,y_test,X_val)#,X_fill = X_fill)\n  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 81, in Train_DNN\n    Mod,callbacks = Dense_Model(params,X_train.shape[1])\n  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 67, in Dense_Model\n    model.add(Dense(params['N'], input_dim=inputs,activation='relu',kernel_initializer=initializer))\n  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 442, in add\n    layer(x)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/core.py\", line 841, in call\n    output = K.dot(inputs, self.kernel)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 998, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 1844, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1289, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(50, 1), b.shape=(1, 8), m=50, n=8, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_dense_1_input_0_0/_19, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_51 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_447_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(50, 1), b.shape=(1, 8), m=50, n=8, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_dense_1_input_0_0/_19, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_51 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_447_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-701261f2032c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mMP\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTV_Split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0mY_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYScaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYScaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NetworkAnalysis/DenseNet.py\u001b[0m in \u001b[0;36mTTV_Split\u001b[0;34m(iteration, params, X, y)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mones_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mones_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mones_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#0.25s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mY_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrain_DNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,X_fill = X_fill)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mX_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NetworkAnalysis/DenseNet.py\u001b[0m in \u001b[0;36mTrain_DNN\u001b[0;34m(params, X_train, y_train, X_test, y_test, X_val)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Print description after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Number of observations per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             validation_data=(X_test, y_test)) # Data for evaluation\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mY_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(50, 1), b.shape=(1, 8), m=50, n=8, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_dense_1_input_0_0/_19, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_51 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_447_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'dense_1/MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-701261f2032c>\", line 57, in <module>\n    results = Dense.TTV_Split(k,params,X,y)\n  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 111, in TTV_Split\n    Y_hat=Train_DNN(params,X_train,y_train,X_test,y_test,X_val)#,X_fill = X_fill)\n  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 81, in Train_DNN\n    Mod,callbacks = Dense_Model(params,X_train.shape[1])\n  File \"/home/ubuntu/NetworkAnalysis/DenseNet.py\", line 67, in Dense_Model\n    model.add(Dense(params['N'], input_dim=inputs,activation='relu',kernel_initializer=initializer))\n  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 442, in add\n    layer(x)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/core.py\", line 841, in call\n    output = K.dot(inputs, self.kernel)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 998, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 1844, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1289, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(50, 1), b.shape=(1, 8), m=50, n=8, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_dense_1_input_0_0/_19, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_51 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_447_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "MP=False\n",
    "Scope = 'Test'\n",
    "cwd = os.getcwd()\n",
    "# for Site in ['Illisarvik','FishIsland']:\n",
    "Site='Illisarvik'\n",
    "target='fch4'\n",
    "\n",
    "# params['Loss']='mean_absolute_error'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    XVarriables=ModSelect(Scope,Site)\n",
    "    prog = FloatProgress(min=0, max=len(XVarriables),description='Running:') # instantiate the bar\n",
    "    display(prog) # display the bar\n",
    "    try:\n",
    "        shutil.rmtree(cwd+'/'+Site+'/'+target+'/')\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(cwd+'/'+Site+'/'+target+'/')\n",
    "    for j in range(1,len(XVarriables)+1):\n",
    "        if j == 1:\n",
    "            Inputs = (Combos(XVarriables,j))\n",
    "        else:\n",
    "            Inputs = (Combos(XVarriables,j,Factors))\n",
    "        i = 0\n",
    "        for Input in Inputs:\n",
    "            params = Dense.Params(Scope,target,MP)\n",
    "            params['Dpath'] = cwd+'/'+Site+'/'\n",
    "            params['Spath'] = params['Dpath']+'/'+target+'/'+str(j)+'_'+str(i)+'/'\n",
    "            try:\n",
    "                os.mkdir(params['Spath'])\n",
    "            except:\n",
    "                pass\n",
    "            params['Sname'] = 'Y_'\n",
    "            params['Inputs'] = Input\n",
    "            params['Model'] = '+'.join(params['Inputs'])\n",
    "\n",
    "            RST = RSTF.ReadStandardTimeFill(params['Dpath']+'ECData.csv',resample='2H')\n",
    "            RST.Scale(params['target'],params['Inputs'])\n",
    "            scaler_filename = \"Y_scaler.save\"\n",
    "            joblib.dump(RST.YScaled, scaler_filename) \n",
    "            scaler_filename = \"X_scaler.save\"\n",
    "            joblib.dump(RST.XScaled, scaler_filename) \n",
    "            y = RST.y*1.0\n",
    "            X = RST.X*1.0\n",
    "\n",
    "            params['N']=int(y.shape[0]/30)\n",
    "#             mse = Test(params,X,y,RST.YScaled,RST.XScaled,pool)\n",
    "            params['Memory'] = (math.floor(100/params['proc'])- 5/params['proc']) * .01\n",
    "            Y_hat=[]\n",
    "            y_true=[]\n",
    "            X_true=[]\n",
    "            index=[]\n",
    "            ones=[]\n",
    "            if MP == False:\n",
    "                for k in range(params['K']):\n",
    "                    results = Dense.TTV_Split(k,params,X,y)\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    index.append(results[3])\n",
    "                    ones.append(results[4])\n",
    "            else:\n",
    "                pool = Pool(processes=3,maxtasksperchild=75)\n",
    "                for k,results in enumerate(pool.imap(partial(Dense.TTV_Split,params=params,X=X,y=y),range(params['K']))):\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    index.append(results[3])\n",
    "                    ones.append(results[4])\n",
    "                pool.close()\n",
    "                \n",
    "#                 tf.keras.backend.clear_session()\n",
    "            Y_hat = np.squeeze(np.asanyarray(Y_hat))\n",
    "            y_true = np.squeeze(np.asanyarray(y_true))\n",
    "            X_true = np.asanyarray(X_true)\n",
    "            index = np.asanyarray(index)\n",
    "            ones = np.asanyarray(ones)\n",
    "            \n",
    "            params['Memory'] = .95\n",
    "            if MP == False:\n",
    "                for k in range(1):\n",
    "                     mse = Dense.Sort_outputs(k,params,Y_hat,y_true,X_true,index,ones)\n",
    "            else:\n",
    "                pool = Pool(processes=1,maxtasksperchild=75)\n",
    "                for k,results in enumerate(pool.imap(partial(Dense.Sort_outputs,params=params,\n",
    "                                                             Y_hat=Y_hat,y_true=y_true,X_true=X_true,index=index,ones=ones),\n",
    "                                                     range(1))):\n",
    "                     mse = results\n",
    "                pool.close()\n",
    "            \n",
    "            if i == 0:\n",
    "                Level = Stats(mse,j,i,params)\n",
    "            else:\n",
    "                Level = Level.append(Stats(mse,j,i,params))\n",
    "            i += 1\n",
    "            print(j+i/len(Inputs),j,i,len(Inputs))\n",
    "            prog.value=j+i/len(Inputs)\n",
    "        Min = Level.loc[Level['MSE']==Level['MSE']].min()\n",
    "        T= 1#t(0.05,params['K'])\n",
    "        Factors = Level.loc[Level['MSE']<=Min['MSE']+Min['SE']*T,'Model'].values\n",
    "        Level.loc[Level['MSE']<=Min['MSE']+Min['SE']*T,'Performance']=1\n",
    "#         print(Level)\n",
    "        \n",
    "        if j == 1:\n",
    "            Records = Level\n",
    "        else:\n",
    "            Records = Records.append(Level)\n",
    "\n",
    "\n",
    "Records = Records.reset_index()\n",
    "plt.figure()\n",
    "Min = Records.loc[Records['MSE']==Records['MSE']].min()\n",
    "Records.loc[Records['MSE']<=Min['MSE']+Min['SE']*T,'Performance']=2\n",
    "Records.loc[Records['MSE']==Min['MSE'],'Performance']=3\n",
    "T= 1#t(0.05,params['K'])\n",
    "Honorable = Records.loc[Records['Performance']==1]\n",
    "Top = Records.loc[Records['Performance']==2]\n",
    "Best = Records.loc[Records['Performance']==3]\n",
    "plt.bar(Honorable.index,Honorable['MSE'],yerr=Honorable['SE'],color='blue')\n",
    "plt.bar(Top.index,Top['MSE'],yerr=Top['SE'],color='green')\n",
    "plt.bar(Best.index,Best['MSE'],yerr=Best['SE'],color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(params['Sname'])\n",
    "params['Spath']=(params['Dpath']+'/'+target+'/'+Best['index'].values[0]+'/')\n",
    "# print(Best['Model'].values[0].split('+'))\n",
    "\n",
    "RST.Scale(params['target'],Best['Model'].values[0].split('+'))\n",
    "# print(Best['index'])\n",
    "# for rm in Worst:\n",
    "#     print(rm)\n",
    "#     shutil.rmtree(params['Dpath']+'/'+target+'/'+rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Fill = False\n",
    "if Fill == True:\n",
    "    X = RST.X_fill\n",
    "else:\n",
    "    X = RST.X\n",
    "print(X.shape)\n",
    "params['Sname']='Y_'\n",
    "# params['Loss']='mean_absolute_error'\n",
    "Y_fill = []\n",
    "# Y_bar = []\n",
    "MSE = []\n",
    "for i in range(params['K']):\n",
    "    params['iteration']=i\n",
    "    Empty_Mod = Dense.Load_Model(params)\n",
    "    Model = Dense.Load_Weights(Empty_Mod,params) \n",
    "    Y = RST.YScaled.inverse_transform(Model.predict(X).reshape(-1,1))\n",
    "#     Y_bar.append(RST.YScaled.inverse_transform(Model.predict(np.median(X,axis=0)).reshape(-1,1)))\n",
    "    if Fill == False:\n",
    "        mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "        MSE.append(mse)\n",
    "    Y_fill.append(Y)\n",
    "Y_fill = np.asanyarray(Y_fill).mean(axis=-1)\n",
    "# Y_bar = np.asanyarray(Y_bar).mean(axis=-1)\n",
    "Y_fill_bar = Y_fill.mean(axis=0)\n",
    "# Y_bar = Y_bar.mean(axis=0)\n",
    "if Fill == False:\n",
    "    MSE = np.asanyarray(MSE)\n",
    "    CI = stats.t.ppf(1-0.025,i)*MSE.std()/(i)**.5\n",
    "    print(CI)\n",
    "    \n",
    "print(Y_bar,Y_fill_bar.mean())\n",
    "\n",
    "params['Sname']='Var'\n",
    "params['iteration']=1\n",
    "params['Loss']='Boot_Loss'\n",
    "Empty_Mod = Dense.Load_Model(params)\n",
    "Model = Dense.Load_Weights(Empty_Mod,params) \n",
    "YVar=YScaled.inverse_transform(Model.predict(X).reshape(-1,1))\n",
    "YVar_bar=YScaled.inverse_transform(Model.predict(X.mean(axis=0)).reshape(-1,1))\n",
    "X_back = np.squeeze(RST.XScaled.inverse_transform(X))\n",
    "\n",
    "print(RST.YScaled.inverse_transform(RST.y).shape,np.squeeze(Y_fill_bar).shape)\n",
    "\n",
    "Data = pd.DataFrame(data=X_back,columns=params['Inputs'])\n",
    "Data[target] = np.squeeze(Y_fill_bar)\n",
    "Data['True'] = RST.Master[target]#.YScaled.inverse_transform(RST.y)\n",
    "Data['SE'] = 1/(params['K']-1)*((Y_fill-Y_fill_bar)**2).sum(axis=0)\n",
    "Data['Var'] = np.squeeze(YVar)\n",
    "Data['CI']=stats.t.ppf(1-0.025,params['K'])*(Data['SE'])**.5\n",
    "Data['PI']=stats.t.ppf(1-0.025,params['K'])*((Data['Var']+Data['SE'])**.5) #the accuracy of our estimate with respect to the observed output\n",
    "\n",
    "print(Data['CI'].mean())\n",
    "print(Data[target].mean())\n",
    "print(Data['True'].mean())\n",
    "Data['Fill'] = Data['True'].fillna(Data[target])\n",
    "print(Data['Fill'].mean())\n",
    "\n",
    "# plt.figure(figsize=(8,7))\n",
    "# Data = Data.sort_values(by='PPFD_Avg')\n",
    "# Data.index = Data.PPFD_Avg\n",
    "\n",
    "\n",
    "# plt.scatter(Data.index,Data['True'],edgecolor='black',facecolor='white')\n",
    "# plt.plot(Data.index,Data[target],label=\n",
    "#         params['target']+' Model\\nRMSE: '+str(np.round(metrics.r2_score(Data['True'],\n",
    "#                                                                    Data[params['target']])**2,3)))\n",
    "# # plt.plot(Data.index,Data['Var'],label= params['target']+\n",
    "# # ' Model\\nRMSE: '+str(np.round(metrics.mean_squared_error(Data['True'],\n",
    "# #                                                                    Data[params['target']])**2,3)))\n",
    "\n",
    "\n",
    "# plt.fill_between(Data.index, Data[target]-Data['PI'], \n",
    "#                  Data[target]+Data['PI'],  color = 'green', alpha = 0.4, \n",
    "#                  label = '95% PI')\n",
    "# plt.fill_between(Data.index, Data[target]-Data['CI'], \n",
    "#                  Data[target]+Data['CI'],  color = 'red', alpha = 0.4, \n",
    "#                  label = '95% CI')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# Y_hat_train,Y_hat_val,y_true,X_true,count_train,\n",
    "#     count_val=Dense.Sort(Y_hat,y_true,X_true,index,ones)    \n",
    "    \n",
    "Y_hat_train_bar=np.nanmean(Y_hat_train,axis=0)\n",
    "Y_hat_val_bar=np.nanmean(Y_hat_val,axis=0)\n",
    "Y_hat_train_var = 1/(np.nansum(count_train)-1)*np.nansum((Y_hat_train - Y_hat_train_bar)**2,axis=0)\n",
    "Y_hat_val_var = 1/(np.nansum(count_val)-1)*np.nansum((Y_hat_val - Y_hat_val_bar)**2,axis=0)\n",
    "r2_train = np.maximum((y_true[0,:]-Y_hat_train_bar)**2-Y_hat_train_var,0)\n",
    "r2_val = np.maximum((y_true[0,:]-Y_hat_val_bar)**2-Y_hat_val_var,0)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_true[0,:],Y_hat_train_bar)\n",
    "print(metrics.mean_squared_error(y_true[0,:],Y_hat_train_bar)**2)\n",
    "print(metrics.r2_score(y_true[0,:],Y_hat_train_bar))\n",
    "print(y_true[0,:].mean(),Y_hat_train_bar.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI and PI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "importlib.reload(Dense)\n",
    "\n",
    "\n",
    "params['Loss'] = 'Boot_Loss'\n",
    "params['Validate'] = False\n",
    "params['Sname'] = 'Var'\n",
    "params['Save']['Model'] = True\n",
    "\n",
    "y = r2_val\n",
    "Valid = np.where(np.isnan(y)==False)\n",
    "y = y[Valid]\n",
    "X = X_true[Valid]\n",
    "\n",
    "YStandard = MinMaxScaler(feature_range=(.1, 1))\n",
    "XStandard = StandardScaler()\n",
    "YScaled = YStandard.fit(y.reshape(-1, 1))\n",
    "XScaled = XStandard.fit(X)#.reshape(-1, 1))\n",
    "y = YScaled.transform(y.reshape(-1, 1))\n",
    "X = XScaled.transform(X)\n",
    "init=1#int(np.random.rand(1)[0]*100)\n",
    "Y_hat_var,y_true_var,X_true_var,index_var,ones_var = Dense.TTV_Split(init,params,X,y)\n",
    "Y_hat_var = YScaled.inverse_transform(Y_hat_var.reshape(-1,1))\n",
    "y_true_var = YScaled.inverse_transform(y_true_var.reshape(-1,1))\n",
    "# plt.figure()\n",
    "# plt.scatter(Y_hat_var,y_true_var)\n",
    "# plt.ylabel('True')\n",
    "# plt.xlabel('prd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The \"Optimum\" Sized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pool.close()\n",
    "# Site = 'Illisarvik'#'FishIsland'#\n",
    "Scope = 'Test'\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# def Params(Func,Y,MP = True):\n",
    "#     params = {}\n",
    "#     params['proc']=3\n",
    "#     if MP == False:\n",
    "#         params['proc']=1\n",
    "#     if Func == 'Full':\n",
    "#         epochs = 200\n",
    "#         K = 30\n",
    "#         splits_per_mod = 1\n",
    "#         N = np.linspace(200,20,10,dtype='int32')\n",
    "#     elif Func == 'Test':\n",
    "#         epochs = 200\n",
    "#         K = 30\n",
    "#         splits_per_mod = 1\n",
    "#         N = np.linspace(70,10,5,dtype='int32')\n",
    "#     N = np.repeat(N,K)\n",
    "#     d = {'N':N.astype(int)}\n",
    "#     Runs = pd.DataFrame(data=d)\n",
    "#     Runs['MAE'] = 0.0\n",
    "#     Runs['R2'] = 0.0\n",
    "#     Runs['Model']=0\n",
    "#     params['K'] = K\n",
    "#     params['epochs'] = epochs\n",
    "#     params['Y'] = Y\n",
    "#     params['splits_per_mod'] = splits_per_mod\n",
    "#     params['Save'] = {}\n",
    "#     params['Save']['Weights']=False\n",
    "#     params['Save']['Model']=False\n",
    "    \n",
    "#     return(Runs,params)\n",
    "\n",
    "\n",
    "# MP=False\n",
    "\n",
    "# if Scope == 'Full':\n",
    "#     MP = True\n",
    "# if __name__=='__main__'and MP==True:\n",
    "#     pool = Pool(processes=3,maxtasksperchild=75)\n",
    "# else:pool=None\n",
    "    \n",
    "# # for Site in ['Illisarvik','FishIsland']:\n",
    "# Site='Illisarvik'\n",
    "# FillVar = 'fco2'\n",
    "# #     for FillVar in ['fco2','fch4']:\n",
    "# Runs,params = MF.Params(Scope,FillVar,MP)\n",
    "# FullModel = ModSelect(Scope,Site)\n",
    "# print(FullModel)\n",
    "# params['Dpath'] = cwd+'/'+Site+'/'\n",
    "# params['Prelim_N']=True\n",
    "# Best,Scores,ModelRuns = MF.FactorTest(params,FullModel,Runs)\n",
    "# print(Best,Scores)\n",
    "# Scores,ModelRuns = Best_Fill(Best,Runs,Scores,params)\n",
    "# Scores.to_csv(params['Dpath']+FillVar+'/GapFillingSummary.csv')\n",
    "# ModelRuns.to_csv(params['Dpath']+FillVar+'/GapFilled.csv')\n",
    "\n",
    "# if __name__=='__main__'and MP==True:\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grp = Scores.groupby('Model').mean()\n",
    "# Grp['SE'] = Scores[['Model','MAE']].groupby('Model').sem()\n",
    "# # Grp['SE'] = Scores[['Key','MAE']].groupby('Key').sem()\n",
    "# print(Grp)\n",
    "# # plt.bar(Grp.index,Grp['MAE'],yerr=Grp['SE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('kitty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
