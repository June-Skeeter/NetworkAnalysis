{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimze and a Dense Neural Network for gap filling and feature identification\n",
    "\n",
    "** With a few tweaks to RepRunner, an LSTM can be run instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Personal Modules\n",
    "import ReadStandardTimeFill as RSTF\n",
    "import importlib\n",
    "import DenseNet as Dense\n",
    "importlib.reload(Dense)\n",
    "importlib.reload(RSTF)\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from matplotlib import cm\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import os\n",
    "# pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTV_Split(iteration,Memory,X,y,params,X_fill):\n",
    "    if params['Save']['Model']==True:\n",
    "        params['Save']['Weights'] = True\n",
    "    params['seed'] = int(iteration%params['splits_per_mod']/params['splits_per_mod']*100)\n",
    "    params['iteration'] = int(iteration/params['splits_per_mod'])\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.1, random_state=params['seed'])\n",
    "    X_train,X_val,y_train,y_val=train_test_split(X_train,y_train, test_size=0.11, random_state=params['seed'])\n",
    "    return(Dense.Train_Steps(params,X_train,X_test,X_val,y_train,y_test,\n",
    "        y_val,X_fill = X_fill,Memory=Memory),\n",
    "        y_val,params)\n",
    "\n",
    "def RunReps(Model,params,Runs):\n",
    "    RST = RSTF.ReadStandardTimeFill(Path)\n",
    "    offset = 5/params['proc']\n",
    "    Memory = (math.floor(100/params['proc'])- offset) * .01\n",
    "    MSE = []\n",
    "    RST.Scale(params['Y'],Model)\n",
    "    y = RST.y*1.0\n",
    "    X = RST.X*1.0\n",
    "    X_fill = RST.X_fill*1.0\n",
    "    Yval = []\n",
    "    y_val= []\n",
    "    for i in range(params['K']):\n",
    "        results = TTV_Split(i,Memory,X,y,params,X_fill)\n",
    "        Yval = RST.YScaled.inverse_transform(results[0][1].reshape(-1,1))\n",
    "        y_val = RST.YScaled.inverse_transform(results[1].reshape(-1,1))\n",
    "        Runs['MSE'].iloc[i] = metrics.mean_squared_error(y_val,Yval)\n",
    "        Runs['R2'].iloc[i] = metrics.r2_score(y_val,Yval)\n",
    "        params=results[2]\n",
    "        Runs['iteration'].iloc[i] = params['iteration']\n",
    "        Runs['seed'].iloc[i] = params['seed']\n",
    "    return(Runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'proc': 1, 'K': 4, 'epochs': 100, 'Y': 'fch4', 'splits_per_mod': 2, 'Save': {'Weights': False, 'Model': True}, 'N': 34, 'Model': 'PPFD_Avg+Sedge'}\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "FillVar = 'fch4'\n",
    "\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "os.chdir('C:/Users/wesle/NetworkAnalysis/')\n",
    "Model = ['PPFD_Avg','Sedge']\n",
    "N = 34\n",
    "\n",
    "Path = 'Data_Footprints_2018-06-12.csv'\n",
    "Runs,params = Dense.Params('Test',FillVar,MP=False)\n",
    "Runs['iteration'] = 0\n",
    "Runs['seed'] = 0\n",
    "\n",
    "params['N'] = N\n",
    "params['Save']['Model'] = True\n",
    "params['Model'] = '+'.join(Model)\n",
    "print(params)\n",
    "Runs = Runs.iloc[0:params['K']].drop('Model',axis=1)\n",
    "Runs['N'] = params['N']\n",
    "Runs = RunReps(Model,params,Runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N         MSE        R2  iteration  seed\n",
      "0  34  110.810935  0.308366          0     0\n",
      "1  34   86.911972  0.318363          0    50\n",
      "2  34  109.359549  0.317425          1     0\n",
      "3  34   83.914782  0.341870          1    50\n"
     ]
    }
   ],
   "source": [
    "print(Runs.groupby('Iteration').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/wesle/ML_GapFilling/fch4/Weights/PPFD_Avg+Sedge.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d6ceabd9928e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReadStandardTimeFill\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRSTF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mjson_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/wesle/ML_GapFilling/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mFillVar\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/Weights/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mloaded_model_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/wesle/ML_GapFilling/fch4/Weights/PPFD_Avg+Sedge.json'"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "import ReadStandardTimeFill as RSTF\n",
    "json_file = open('C:/Users/wesle/NetworkAnalysis/'+FillVar+'/Weights/'+params['Model']+'.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "# Min = \n",
    "loaded_model.load_weights('C:/Users/wesle/NetworkAnalysis/'+FillVar+'/Weights/'+params['Model']+'_0_0.h5')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# FullModel = fco2_summary.loc[fco2_summary['Level']==0,'Model'].values[0].split('+')\n",
    "\n",
    "for i in range(2):\n",
    "    RST = RSTF.ReadStandardTimeFill('Data_Footprints_2018-06-12.csv')\n",
    "    RST.Scale('fch4',Model)\n",
    "    y = RST.y*1.0\n",
    "    X = RST.X*1.0\n",
    "    print(X.shape)\n",
    "#     if i == 0:\n",
    "#         X[:,0]=X[:,0].min()\n",
    "#     if i == 1:\n",
    "#         X[:,0]=X[:,0].mean()\n",
    "#     if i == 2:\n",
    "#         X[:,0]=X[:,0].max()\n",
    "    loaded_model.compile(loss='mean_squared_error', optimizer='adam')#loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#     score = loaded_model.evaluate(X, y, verbose=1)\n",
    "    rest = loaded_model.predict(X)\n",
    "    rest = RST.YScaled.inverse_transform(rest.reshape(-1,1))\n",
    "    X = RST.XScaled.inverse_transform(X)\n",
    "#     print(score)\n",
    "    plt.scatter(X[:,1],rest,label=X[:,0].mean())\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bee9b37f0874e058542e8cf2146f5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Time = time.time()\n",
    "# def RunLoop(Runs):\n",
    "    \n",
    "#     f = FloatProgress(min=0, max=Runs['N'].count()) # instantiate the bar\n",
    "#     display(f) # display the bar\n",
    "# #     print(Runs)\n",
    "#     for N in Runs['N'].unique():   \n",
    "#         f.value+=params['K']\n",
    "#         params['T'] = 0\n",
    "#         params['N']=N\n",
    "#         Results = RunReps(FullModel,params,pool)\n",
    "#         MSE = Results[0]\n",
    "#         R2 = Results[1]\n",
    "#         Runs.loc[Runs['N']==N,'MSE']=MSE\n",
    "#         Runs.loc[Runs['N']==N,'R2']=R2\n",
    "# #         print(Runs.loc[Runs['N']==N])\n",
    "#     return(Runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
