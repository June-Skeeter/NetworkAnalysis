{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimze and a Dense Neural Network for gap filling and feature identification\n",
    "\n",
    "** With a few tweaks to RepRunner, an LSTM can be run instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "# from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from sklearn import metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Personal Modules\n",
    "import ReadStandardTimeFill as RSTF\n",
    "import importlib\n",
    "import DenseNet as Dense\n",
    "import MiscFuncs as MF\n",
    "importlib.reload(Dense)\n",
    "importlib.reload(RSTF)\n",
    "importlib.reload(MF)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.externals import joblib\n",
    "from matplotlib import cm\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import os  \n",
    "from functools import partial\n",
    "import shutil\n",
    "from keras import backend as K\n",
    "try:pool.close()\n",
    "except:pass\n",
    "\n",
    "\n",
    "def Test(params,X,y,YScaled,XScaled,pool):\n",
    "    return(np.random.rand(params['K']))\n",
    "\n",
    "\n",
    "def ModSelect(Scope,Site):\n",
    "    if Site == 'Illisarvik':\n",
    "        if Scope == 'Full':\n",
    "            Model = ['H','wind_speed','air_pressure','PPFD_Avg','AirTC_Avg','VPD',\n",
    "                    'Temp','VWC','Sedge','Shrub','Grass','Sparse','Out_of_Basin']\n",
    "        if Scope == 'Test':\n",
    "            Model = ['PPFD_Avg','wind_speed']#,'Temp','VWC','Sedge']\n",
    "    if Site == 'FishIsland':\n",
    "        BaseFactors = []\n",
    "        if Scope == 'Full':\n",
    "            Model = ['H','Wind Spd','air pressure','Ta','Rn','PPFD','Rain','Water Table',\n",
    "            'Ts 2.5 cm','Ts 15 cm','VWC','Active Layer','24H Rain','Wtr Tbl Trnd']\n",
    "        if Scope == 'Test':\n",
    "            Model = ['H','Water Table','Wind Spd','Active Layer']\n",
    "    return(Model)\n",
    "\n",
    "def Combos(Model,L,factor=None):\n",
    "    Models=[]\n",
    "    for c in combinations(Model,L):\n",
    "        c = list(c)\n",
    "        if factor is None:\n",
    "            Models.append(c)\n",
    "        else:\n",
    "            for f in factor:\n",
    "                f = f.split('+')\n",
    "                if set(f).issubset(set(c)) and c not in Models:\n",
    "                    Models.append(c)\n",
    "                    \n",
    "    print('Models: ',Models)\n",
    "    return(Models)\n",
    "\n",
    "def Stats(mse,j,i,params):\n",
    "    df = pd.DataFrame(index = [str(j)+'_'+str(i)],\n",
    "                      data={'Model':[params['Model']],\n",
    "                            'MSE':[mse.mean()],\n",
    "                            'SE':[mse.std()/params['K']**.5],\n",
    "                            'Performance':0})\n",
    "    return(df)\n",
    "\n",
    "def t(p,n):\n",
    "    alpha = 1-p\n",
    "    df = n-1\n",
    "    return(stats.t.ppf(alpha,df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615b827d8567442e8bd2968681f5e32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models:  [['PPFD_Avg'], ['wind_speed']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7bc703ae11a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mscaler_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Y_scaler.save\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYStandard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mscaler_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"X_scaler.save\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXStandard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "MP=True\n",
    "Scope = 'Test'\n",
    "cwd = os.getcwd()\n",
    "# for Site in ['Illisarvik','FishIsland']:\n",
    "Site='Illisarvik'\n",
    "target='fch4'\n",
    "\n",
    "# params['Loss']='mean_absolute_error'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    XVarriables=ModSelect(Scope,Site)\n",
    "    prog = FloatProgress(min=0, max=len(XVarriables),description='Running:') # instantiate the bar\n",
    "    display(prog) # display the bar\n",
    "    try:\n",
    "        shutil.rmtree(cwd+'/'+Site+'/'+target+'/')\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(cwd+'/'+Site+'/'+target+'/')\n",
    "    for j in range(1,len(XVarriables)+1):\n",
    "        if j == 1:\n",
    "            Inputs = (Combos(XVarriables,j))\n",
    "        else:\n",
    "            Inputs = (Combos(XVarriables,j,Factors))\n",
    "        i = 0\n",
    "        for Input in Inputs:\n",
    "            params = Dense.Params(Scope,target,MP)\n",
    "            params['Dpath'] = cwd+'/'+Site+'/'\n",
    "            params['Spath'] = params['Dpath']+'/'+target+'/'+str(j)+'_'+str(i)+'/'\n",
    "            try:\n",
    "                os.mkdir(params['Spath'])\n",
    "            except:\n",
    "                pass\n",
    "            scaler_filename = \"Y_scaler.save\"\n",
    "            joblib.dump(RST.YStandard, scaler_filename) \n",
    "            scaler_filename = \"X_scaler.save\"\n",
    "            joblib.dump(RST.XStandard, scaler_filename) \n",
    "            params['Sname'] = 'Y_'\n",
    "            params['Inputs'] = Input\n",
    "            params['Model'] = '+'.join(params['Inputs'])\n",
    "\n",
    "            RST = RSTF.ReadStandardTimeFill(params['Dpath']+'ECData.csv',resample='2H')\n",
    "            RST.Scale(params['target'],params['Inputs'])\n",
    "            y = RST.y*1.0\n",
    "            X = RST.X*1.0\n",
    "\n",
    "            params['N']=int(y.shape[0]/30)\n",
    "#             mse = Test(params,X,y,RST.YScaled,RST.XScaled,pool)\n",
    "            params['Memory'] = (math.floor(100/params['proc'])- 5/params['proc']) * .01\n",
    "            Y_hat=[]\n",
    "            y_true=[]\n",
    "            X_true=[]\n",
    "            index=[]\n",
    "            ones=[]\n",
    "            if MP == False:\n",
    "                for k in range(params['K']):\n",
    "                    results = Dense.TTV_Split(k,params,X,y)\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    index.append(results[3])\n",
    "                    ones.append(results[4])\n",
    "            else:\n",
    "                pool = Pool(processes=3,maxtasksperchild=75)\n",
    "                for k,results in enumerate(pool.imap(partial(Dense.TTV_Split,params=params,X=X,y=y),range(params['K']))):\n",
    "                    Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                    y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                    X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                    index.append(results[3])\n",
    "                    ones.append(results[4])\n",
    "                pool.close()\n",
    "                \n",
    "#                 tf.keras.backend.clear_session()\n",
    "            Y_hat = np.squeeze(np.asanyarray(Y_hat))\n",
    "            y_true = np.squeeze(np.asanyarray(y_true))\n",
    "            X_true = np.asanyarray(X_true)\n",
    "            index = np.asanyarray(index)\n",
    "            ones = np.asanyarray(ones)\n",
    "            \n",
    "            params['Memory'] = .95\n",
    "            if MP == False:\n",
    "                for k in range(1):\n",
    "                     mse = Dense.Sort_outputs(k,params,Y_hat,y_true,X_true,index,ones)\n",
    "            else:\n",
    "                pool = Pool(processes=1,maxtasksperchild=75)\n",
    "                for k,results in enumerate(pool.imap(partial(Dense.Sort_outputs,params=params,\n",
    "                                                             Y_hat=Y_hat,y_true=y_true,X_true=X_true,index=index,ones=ones),\n",
    "                                                     range(1))):\n",
    "                     mse = results\n",
    "                pool.close()\n",
    "            \n",
    "            if i == 0:\n",
    "                Level = Stats(mse,j,i,params)\n",
    "            else:\n",
    "                Level = Level.append(Stats(mse,j,i,params))\n",
    "            i += 1\n",
    "            print(j+i/len(Inputs),j,i,len(Inputs))\n",
    "            prog.value=j+i/len(Inputs)\n",
    "        Min = Level.loc[Level['MSE']==Level['MSE']].min()\n",
    "        T= 1#t(0.05,params['K'])\n",
    "        Factors = Level.loc[Level['MSE']<=Min['MSE']+Min['SE']*T,'Model'].values\n",
    "        Level.loc[Level['MSE']<=Min['MSE']+Min['SE']*T,'Performance']=1\n",
    "#         print(Level)\n",
    "        \n",
    "        if j == 1:\n",
    "            Records = Level\n",
    "        else:\n",
    "            Records = Records.append(Level)\n",
    "\n",
    "\n",
    "Records = Records.reset_index()\n",
    "plt.figure()\n",
    "Min = Records.loc[Records['MSE']==Records['MSE']].min()\n",
    "Records.loc[Records['MSE']<=Min['MSE']+Min['SE']*T,'Performance']=2\n",
    "Records.loc[Records['MSE']==Min['MSE'],'Performance']=3\n",
    "T= 1#t(0.05,params['K'])\n",
    "Honorable = Records.loc[Records['Performance']==1]\n",
    "Top = Records.loc[Records['Performance']==2]\n",
    "Best = Records.loc[Records['Performance']==3]\n",
    "plt.bar(Honorable.index,Honorable['MSE'],yerr=Honorable['SE'],color='blue')\n",
    "plt.bar(Top.index,Top['MSE'],yerr=Top['SE'],color='green')\n",
    "plt.bar(Best.index,Best['MSE'],yerr=Best['SE'],color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(params['Sname'])\n",
    "params['Spath']=(params['Dpath']+'/'+target+'/'+Best['index'].values[0]+'/')\n",
    "# print(Best['Model'].values[0].split('+'))\n",
    "\n",
    "RST.Scale(params['target'],Best['Model'].values[0].split('+'))\n",
    "# print(Best['index'])\n",
    "# for rm in Worst:\n",
    "#     print(rm)\n",
    "#     shutil.rmtree(params['Dpath']+'/'+target+'/'+rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Fill = False\n",
    "if Fill == True:\n",
    "    X = RST.X_fill\n",
    "else:\n",
    "    X = RST.X\n",
    "print(X.shape)\n",
    "params['Sname']='Y_'\n",
    "# params['Loss']='mean_absolute_error'\n",
    "Y_fill = []\n",
    "# Y_bar = []\n",
    "MSE = []\n",
    "for i in range(params['K']):\n",
    "    params['iteration']=i\n",
    "    Empty_Mod = Dense.Load_Model(params)\n",
    "    Model = Dense.Load_Weights(Empty_Mod,params) \n",
    "    Y = RST.YScaled.inverse_transform(Model.predict(X).reshape(-1,1))\n",
    "#     Y_bar.append(RST.YScaled.inverse_transform(Model.predict(np.median(X,axis=0)).reshape(-1,1)))\n",
    "    if Fill == False:\n",
    "        mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "        MSE.append(mse)\n",
    "    Y_fill.append(Y)\n",
    "Y_fill = np.asanyarray(Y_fill).mean(axis=-1)\n",
    "# Y_bar = np.asanyarray(Y_bar).mean(axis=-1)\n",
    "Y_fill_bar = Y_fill.mean(axis=0)\n",
    "# Y_bar = Y_bar.mean(axis=0)\n",
    "if Fill == False:\n",
    "    MSE = np.asanyarray(MSE)\n",
    "    CI = stats.t.ppf(1-0.025,i)*MSE.std()/(i)**.5\n",
    "    print(CI)\n",
    "    \n",
    "print(Y_bar,Y_fill_bar.mean())\n",
    "\n",
    "params['Sname']='Var'\n",
    "params['iteration']=1\n",
    "params['Loss']='Boot_Loss'\n",
    "Empty_Mod = Dense.Load_Model(params)\n",
    "Model = Dense.Load_Weights(Empty_Mod,params) \n",
    "YVar=YScaled.inverse_transform(Model.predict(X).reshape(-1,1))\n",
    "YVar_bar=YScaled.inverse_transform(Model.predict(X.mean(axis=0)).reshape(-1,1))\n",
    "X_back = np.squeeze(RST.XScaled.inverse_transform(X))\n",
    "\n",
    "print(RST.YScaled.inverse_transform(RST.y).shape,np.squeeze(Y_fill_bar).shape)\n",
    "\n",
    "Data = pd.DataFrame(data=X_back,columns=params['Inputs'])\n",
    "Data[target] = np.squeeze(Y_fill_bar)\n",
    "Data['True'] = RST.Master[target]#.YScaled.inverse_transform(RST.y)\n",
    "Data['SE'] = 1/(params['K']-1)*((Y_fill-Y_fill_bar)**2).sum(axis=0)\n",
    "Data['Var'] = np.squeeze(YVar)\n",
    "Data['CI']=stats.t.ppf(1-0.025,params['K'])*(Data['SE'])**.5\n",
    "Data['PI']=stats.t.ppf(1-0.025,params['K'])*((Data['Var']+Data['SE'])**.5) #the accuracy of our estimate with respect to the observed output\n",
    "\n",
    "print(Data['CI'].mean())\n",
    "print(Data[target].mean())\n",
    "print(Data['True'].mean())\n",
    "Data['Fill'] = Data['True'].fillna(Data[target])\n",
    "print(Data['Fill'].mean())\n",
    "\n",
    "# plt.figure(figsize=(8,7))\n",
    "# Data = Data.sort_values(by='PPFD_Avg')\n",
    "# Data.index = Data.PPFD_Avg\n",
    "\n",
    "\n",
    "# plt.scatter(Data.index,Data['True'],edgecolor='black',facecolor='white')\n",
    "# plt.plot(Data.index,Data[target],label=\n",
    "#         params['target']+' Model\\nRMSE: '+str(np.round(metrics.r2_score(Data['True'],\n",
    "#                                                                    Data[params['target']])**2,3)))\n",
    "# # plt.plot(Data.index,Data['Var'],label= params['target']+\n",
    "# # ' Model\\nRMSE: '+str(np.round(metrics.mean_squared_error(Data['True'],\n",
    "# #                                                                    Data[params['target']])**2,3)))\n",
    "\n",
    "\n",
    "# plt.fill_between(Data.index, Data[target]-Data['PI'], \n",
    "#                  Data[target]+Data['PI'],  color = 'green', alpha = 0.4, \n",
    "#                  label = '95% PI')\n",
    "# plt.fill_between(Data.index, Data[target]-Data['CI'], \n",
    "#                  Data[target]+Data['CI'],  color = 'red', alpha = 0.4, \n",
    "#                  label = '95% CI')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# Y_hat_train,Y_hat_val,y_true,X_true,count_train,\n",
    "#     count_val=Dense.Sort(Y_hat,y_true,X_true,index,ones)    \n",
    "    \n",
    "Y_hat_train_bar=np.nanmean(Y_hat_train,axis=0)\n",
    "Y_hat_val_bar=np.nanmean(Y_hat_val,axis=0)\n",
    "Y_hat_train_var = 1/(np.nansum(count_train)-1)*np.nansum((Y_hat_train - Y_hat_train_bar)**2,axis=0)\n",
    "Y_hat_val_var = 1/(np.nansum(count_val)-1)*np.nansum((Y_hat_val - Y_hat_val_bar)**2,axis=0)\n",
    "r2_train = np.maximum((y_true[0,:]-Y_hat_train_bar)**2-Y_hat_train_var,0)\n",
    "r2_val = np.maximum((y_true[0,:]-Y_hat_val_bar)**2-Y_hat_val_var,0)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_true[0,:],Y_hat_train_bar)\n",
    "print(metrics.mean_squared_error(y_true[0,:],Y_hat_train_bar)**2)\n",
    "print(metrics.r2_score(y_true[0,:],Y_hat_train_bar))\n",
    "print(y_true[0,:].mean(),Y_hat_train_bar.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI and PI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "importlib.reload(Dense)\n",
    "\n",
    "\n",
    "params['Loss'] = 'Boot_Loss'\n",
    "params['Validate'] = False\n",
    "params['Sname'] = 'Var'\n",
    "params['Save']['Model'] = True\n",
    "\n",
    "y = r2_val\n",
    "Valid = np.where(np.isnan(y)==False)\n",
    "y = y[Valid]\n",
    "X = X_true[Valid]\n",
    "\n",
    "YStandard = MinMaxScaler(feature_range=(.1, 1))\n",
    "XStandard = StandardScaler()\n",
    "YScaled = YStandard.fit(y.reshape(-1, 1))\n",
    "XScaled = XStandard.fit(X)#.reshape(-1, 1))\n",
    "y = YScaled.transform(y.reshape(-1, 1))\n",
    "X = XScaled.transform(X)\n",
    "init=1#int(np.random.rand(1)[0]*100)\n",
    "Y_hat_var,y_true_var,X_true_var,index_var,ones_var = Dense.TTV_Split(init,params,X,y)\n",
    "Y_hat_var = YScaled.inverse_transform(Y_hat_var.reshape(-1,1))\n",
    "y_true_var = YScaled.inverse_transform(y_true_var.reshape(-1,1))\n",
    "# plt.figure()\n",
    "# plt.scatter(Y_hat_var,y_true_var)\n",
    "# plt.ylabel('True')\n",
    "# plt.xlabel('prd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The \"Optimum\" Sized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pool.close()\n",
    "# Site = 'Illisarvik'#'FishIsland'#\n",
    "Scope = 'Test'\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# def Params(Func,Y,MP = True):\n",
    "#     params = {}\n",
    "#     params['proc']=3\n",
    "#     if MP == False:\n",
    "#         params['proc']=1\n",
    "#     if Func == 'Full':\n",
    "#         epochs = 200\n",
    "#         K = 30\n",
    "#         splits_per_mod = 1\n",
    "#         N = np.linspace(200,20,10,dtype='int32')\n",
    "#     elif Func == 'Test':\n",
    "#         epochs = 200\n",
    "#         K = 30\n",
    "#         splits_per_mod = 1\n",
    "#         N = np.linspace(70,10,5,dtype='int32')\n",
    "#     N = np.repeat(N,K)\n",
    "#     d = {'N':N.astype(int)}\n",
    "#     Runs = pd.DataFrame(data=d)\n",
    "#     Runs['MAE'] = 0.0\n",
    "#     Runs['R2'] = 0.0\n",
    "#     Runs['Model']=0\n",
    "#     params['K'] = K\n",
    "#     params['epochs'] = epochs\n",
    "#     params['Y'] = Y\n",
    "#     params['splits_per_mod'] = splits_per_mod\n",
    "#     params['Save'] = {}\n",
    "#     params['Save']['Weights']=False\n",
    "#     params['Save']['Model']=False\n",
    "    \n",
    "#     return(Runs,params)\n",
    "\n",
    "\n",
    "# MP=False\n",
    "\n",
    "# if Scope == 'Full':\n",
    "#     MP = True\n",
    "# if __name__=='__main__'and MP==True:\n",
    "#     pool = Pool(processes=3,maxtasksperchild=75)\n",
    "# else:pool=None\n",
    "    \n",
    "# # for Site in ['Illisarvik','FishIsland']:\n",
    "# Site='Illisarvik'\n",
    "# FillVar = 'fco2'\n",
    "# #     for FillVar in ['fco2','fch4']:\n",
    "# Runs,params = MF.Params(Scope,FillVar,MP)\n",
    "# FullModel = ModSelect(Scope,Site)\n",
    "# print(FullModel)\n",
    "# params['Dpath'] = cwd+'/'+Site+'/'\n",
    "# params['Prelim_N']=True\n",
    "# Best,Scores,ModelRuns = MF.FactorTest(params,FullModel,Runs)\n",
    "# print(Best,Scores)\n",
    "# Scores,ModelRuns = Best_Fill(Best,Runs,Scores,params)\n",
    "# Scores.to_csv(params['Dpath']+FillVar+'/GapFillingSummary.csv')\n",
    "# ModelRuns.to_csv(params['Dpath']+FillVar+'/GapFilled.csv')\n",
    "\n",
    "# if __name__=='__main__'and MP==True:\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grp = Scores.groupby('Model').mean()\n",
    "# Grp['SE'] = Scores[['Model','MAE']].groupby('Model').sem()\n",
    "# # Grp['SE'] = Scores[['Key','MAE']].groupby('Key').sem()\n",
    "# print(Grp)\n",
    "# # plt.bar(Grp.index,Grp['MAE'],yerr=Grp['SE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('kitty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
