{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimze and a Dense Neural Network for gap filling and feature identification\n",
    "\n",
    "** With a few tweaks to RepRunner, an LSTM can be run instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\NetworkAnalysis\n",
      ":o\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "# from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Personal Modules\n",
    "import ReadStandardTimeFill as RSTF\n",
    "import importlib\n",
    "import DenseNet as Dense\n",
    "import MiscFuncs as MF\n",
    "importlib.reload(Dense)\n",
    "importlib.reload(RSTF)\n",
    "importlib.reload(MF)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.externals import joblib\n",
    "from matplotlib import cm\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "from ipywidgets import FloatProgress, HTML\n",
    "from IPython.display import display, clear_output\n",
    "import os  \n",
    "import shutil\n",
    "from keras import backend as K\n",
    "try:pool.close()\n",
    "except:pass\n",
    "\n",
    "\n",
    "def Test(params,X,y,YScaled,XScaled,pool):\n",
    "    return(np.random.rand(params['K']))\n",
    "\n",
    "\n",
    "def ModSelect(Scope,Site):\n",
    "    if Site == 'Illisarvik':\n",
    "        if Scope == 'Full':\n",
    "#             Model = ['wind_speed','PPFD_Avg','AirTC_Avg','VPD',\n",
    "#                     'Temp','VWC','Sedge','Shrub','Grass','Upland']\n",
    "            Model = ['wind_speed','PPFD_Avg','AirTC_Avg','VPD',\n",
    "                    'Temp','VWC','Sedge','Shrub','Grass','Out_of_Basin']\n",
    "        if Scope == 'Test':\n",
    "            Model = ['PPFD_Avg','Upland','wind_speed']\n",
    "    if Site == 'FishIsland':\n",
    "        BaseFactors = []\n",
    "        if Scope == 'Full':\n",
    "            Model = ['Wind Spd','u*','air pressure','Ta','VPD','Rn','PPFD','Water Table','Active Layer',\n",
    "         'Ts 2.5 cm Cent','Ts 5 cm Cent','Ts 15 cm Cent','Ts 2.5 cm Rim','Ts 5 cm Rim','Ts 15 cm Rim','VWC']\n",
    "#             'H','LE','24H Rain','Ts All Cent','Ts All Rim','VWC',\n",
    "        if Scope == 'Test':\n",
    "            Model = ['Wind Spd','Ta','Rn','PPFD','Water Table',\n",
    "            'Ts 2.5 cm','Ts 15 cm','VWC','Active Layer','24H Rain']\n",
    "    return(Model)\n",
    "\n",
    "def Combos(Model,L,factor=None):\n",
    "    Models=[]\n",
    "    for c in combinations(Model,L):\n",
    "        c = list(c)\n",
    "        if factor is None:\n",
    "            Models.append(c)\n",
    "        else:\n",
    "            for f in factor:\n",
    "                f = f.split('+')\n",
    "                if set(f).issubset(set(c)) and c not in Models:\n",
    "                    Models.append(c)\n",
    "                    \n",
    "#     print('Models: ',Models)\n",
    "    return(Models)\n",
    "\n",
    "def Stats(mse,se,j,i,params):\n",
    "    df = pd.DataFrame(index = [str(j)+'_'+str(i)],\n",
    "                      data={'Model':[params['Model']],\n",
    "                            'MSE':[mse],\n",
    "                            'Size':j,\n",
    "                            'Number':i,\n",
    "                            'SE':[se],\n",
    "                            'Performance':0})\n",
    "    return(df)\n",
    "\n",
    "def t(p,n):\n",
    "    alpha = 1-p\n",
    "    df = n-1\n",
    "    return(stats.t.ppf(alpha,df))\n",
    "\n",
    "FirstRun = True\n",
    "# FirstRun = False\n",
    "\n",
    "MP=True\n",
    "# MP=False\n",
    "Scope = 'Full'\n",
    "# Scope = 'Test'\n",
    "# if Scope == Test:\n",
    "#     processes=2\n",
    "# else:\n",
    "processes=3\n",
    "    \n",
    "cwd = os.getcwd()\n",
    "# for Site in ['Illisarvik','FishIsland']:\n",
    "# Site='FishIsland'\n",
    "Site = 'Illisarvik'\n",
    "target='fch4'\n",
    "alpha = .05\n",
    "print(cwd)\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth',200)\n",
    "def Display (tar,prog1,prog2,MdLs,MdL):\n",
    "    clear_output()\n",
    "    display(tar)\n",
    "    display(prog1)\n",
    "    display(prog2)\n",
    "    display(MdLs)\n",
    "    display(MdL)\n",
    "    \n",
    "tar = HTML(\n",
    "            value=\" \",\n",
    "            placeholder='Target: ',\n",
    "            description='Target: ',\n",
    "        )\n",
    "kwt = HTML(\n",
    "        value=str(0),\n",
    "        placeholder='Quit Score: ',\n",
    "        description='Quit Score: ',\n",
    "        )\n",
    "print(':o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110bcaf24b1c471ca9eb29d2f9c40fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='fco2', description='Target: ', placeholder='Target: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc0dbd1df9646fda4a3be4686c3d02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=1.0, description='Running:', max=2.0, min=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da727735251745ba884e7f67e53c4546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, description='Bootstrapping:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3ee8fd042c45a18a1ab7b46385b017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=' ', description='Models: ', placeholder='Models: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3417445bf36a45188a7ea66ac5d6c6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"#99 ['PPFD_Avg', 'VPD', 'VWC', 'Shrub']\", description='Testing: ', placeholder='Testing: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2016-07-12 00:30:00    0.289345\n",
      "2016-07-14 23:30:00    0.288572\n",
      "2016-07-15 22:30:00         NaN\n",
      "2016-07-16 00:00:00         NaN\n",
      "2016-07-16 23:30:00    0.474627\n",
      "2016-07-17 00:00:00         NaN\n",
      "2016-07-17 00:30:00    0.408520\n",
      "2016-07-17 23:30:00    0.331692\n",
      "2016-07-18 00:00:00    0.363145\n",
      "2016-07-18 00:30:00    0.370406\n",
      "2016-07-18 01:00:00         NaN\n",
      "2016-07-18 23:30:00    0.400531\n",
      "2016-07-19 00:00:00    0.385165\n",
      "2016-07-19 00:30:00    0.120697\n",
      "2016-07-19 01:00:00    0.608168\n",
      "2016-07-19 02:00:00         NaN\n",
      "2016-07-19 22:30:00         NaN\n",
      "2016-07-19 23:00:00         NaN\n",
      "2016-07-19 23:30:00         NaN\n",
      "2016-07-20 00:00:00         NaN\n",
      "2016-07-20 00:30:00         NaN\n",
      "2016-07-20 21:30:00         NaN\n",
      "2016-07-20 22:00:00         NaN\n",
      "2016-07-20 22:30:00         NaN\n",
      "2016-07-20 23:00:00         NaN\n",
      "2016-07-20 23:30:00         NaN\n",
      "2016-07-21 00:00:00         NaN\n",
      "2016-07-21 00:30:00         NaN\n",
      "2016-07-21 01:00:00         NaN\n",
      "2016-07-21 01:30:00         NaN\n",
      "                         ...   \n",
      "2016-08-04 02:00:00    0.348236\n",
      "2016-08-04 21:30:00    0.248963\n",
      "2016-08-04 22:00:00    0.253166\n",
      "2016-08-04 22:30:00    0.342478\n",
      "2016-08-04 23:00:00    0.323752\n",
      "2016-08-04 23:30:00    0.325829\n",
      "2016-08-05 00:00:00    0.328502\n",
      "2016-08-05 00:30:00         NaN\n",
      "2016-08-05 01:00:00    0.223120\n",
      "2016-08-05 01:30:00    0.304145\n",
      "2016-08-05 02:00:00    0.217580\n",
      "2016-08-05 02:30:00    0.188683\n",
      "2016-08-05 22:00:00    0.327231\n",
      "2016-08-05 22:30:00    0.341751\n",
      "2016-08-05 23:00:00    0.397681\n",
      "2016-08-05 23:30:00    0.386051\n",
      "2016-08-06 00:00:00    0.443953\n",
      "2016-08-06 00:30:00    0.325836\n",
      "2016-08-06 01:00:00    0.461718\n",
      "2016-08-06 01:30:00    0.411982\n",
      "2016-08-06 02:00:00    0.438275\n",
      "2016-08-06 22:00:00    0.415069\n",
      "2016-08-06 22:30:00    0.447453\n",
      "2016-08-06 23:00:00    0.480170\n",
      "2016-08-06 23:30:00    0.417599\n",
      "2016-08-07 00:00:00    0.431558\n",
      "2016-08-07 00:30:00    0.378646\n",
      "2016-08-07 01:00:00    0.437001\n",
      "2016-08-07 01:30:00    0.463917\n",
      "2016-08-07 02:00:00    0.473072\n",
      "Name: fco2, Length: 150, dtype: float64\n",
      "{'proc': 3, 'K': 30, 'epochs': 1000, 'target': 'fco2', 'Save': {'Weights': True, 'Model': True}, 'Loss': 'mean_squared_error', 'Memory': 0.3, 'validation_split': 0.2, 'iteration': 1, 'Eval': True, 'Dpath': 'C:\\\\Users\\\\wesle\\\\NetworkAnalysis/Illisarvik/', 'Spath': 'C:\\\\Users\\\\wesle\\\\NetworkAnalysis/Illisarvik/ER/99_99/', 'Sname': 'Y_', 'Inputs': ['PPFD_Avg', 'VPD', 'VWC', 'Shrub'], 'Model': 'PPFD_Avg+VPD+VWC+Shrub'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "prog1 = FloatProgress(min=1, max=2,description='Running:')\n",
    "prog2 = FloatProgress(min=0, max=100,description='Bootstrapping:')\n",
    "MdLs = HTML(\n",
    "    value=\" \",\n",
    "    placeholder='Models: ',\n",
    "    description='Models: ',\n",
    ")\n",
    "MdL = HTML(\n",
    "    value=\" \",\n",
    "    placeholder='Testing: ',\n",
    "    description='Testing: ',\n",
    ")\n",
    "Display (tar,prog1,prog2,MdLs,MdL)\n",
    "\n",
    "i = 99\n",
    "j = 99\n",
    "target = 'fco2'\n",
    "Name ='ER'\n",
    "tar.value=target\n",
    "\n",
    "params = Dense.Params(Scope,target,MP)\n",
    "# params['K']=15\n",
    "params['Dpath'] = cwd+'/'+Site+'/'\n",
    "params['Spath'] = params['Dpath']+Name+'/'+str(j)+'_'+str(i)+'/'\n",
    "try:\n",
    "    os.mkdir(params['Spath'])\n",
    "except:\n",
    "    pass\n",
    "params['Sname'] = 'Y_'\n",
    "# params['Inputs'] = ['PPFD_Avg','VPD']#Input\n",
    "# params['Inputs'] = ['PPFD_Avg','VPD','VWC','Shrub']#Input\n",
    "\n",
    "params['Inputs'] = ['PPFD_Avg','VPD','VWC','Shrub']\n",
    "\n",
    "MdL.value='#'+str(i)+' '+str(params['Inputs'])\n",
    "Display (tar,prog1,prog2,MdLs,MdL)\n",
    "params['Model'] = '+'.join(params['Inputs'])\n",
    "RST = RSTF.ReadStandardTimeFill(params,'ECData.csv')#,resample='2H')\n",
    "\n",
    "# if Name =='ER':\n",
    "#     RST.Master = RST.Master.loc[RST.Master['fco2']>.05]\n",
    "if Name =='ER':\n",
    "    RST.Master = RST.Master.loc[(RST.Master['PPFD_Avg']<10)]#&(RST.Master['fco2']>.0)]\n",
    "\n",
    "print(RST.Master['fco2'])\n",
    "# print(RST.Master.sort_values(by='fco2')['fco2'])\n",
    "\n",
    "RST.Scale(params['target'],params['Inputs']) \n",
    "y_Set = RST.y*1.0\n",
    "X_Set = RST.X*1.0\n",
    "\n",
    "X,y = resample(X_Set,y_Set, n_samples=y_Set.shape[0]*1.5)\n",
    "\n",
    "print(params)\n",
    "\n",
    "\n",
    "# if MP == False:\n",
    "#     for k in range(1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 202) (30, 202)\n",
      "Var!!\n",
      "[[0.10215258]\n",
      " [0.10325752]\n",
      " [0.11921276]\n",
      " [0.10843109]\n",
      " [0.11310881]\n",
      " [0.10020275]\n",
      " [0.10000001]\n",
      " [0.10683302]\n",
      " [0.11966609]\n",
      " [0.10215258]\n",
      " [0.10564562]\n",
      " [0.16127638]\n",
      " [0.10000001]\n",
      " [0.13384152]\n",
      " [0.10511731]\n",
      " [0.10240669]\n",
      " [0.1005116 ]\n",
      " [0.10128426]\n",
      " [0.10744479]\n",
      " [0.10020325]\n",
      " [0.10497911]\n",
      " [0.13384152]\n",
      " [0.1100103 ]\n",
      " [0.10431081]\n",
      " [0.10303275]\n",
      " [0.12364235]\n",
      " [0.1009331 ]\n",
      " [0.11167   ]\n",
      " [0.19167453]\n",
      " [0.10002154]\n",
      " [0.1701596 ]\n",
      " [0.10862606]\n",
      " [0.1009331 ]\n",
      " [0.10564562]\n",
      " [0.1023742 ]\n",
      " [0.10015133]\n",
      " [0.93416668]\n",
      " [0.14501813]\n",
      " [0.10240669]\n",
      " [0.10128426]\n",
      " [0.12157743]\n",
      " [0.10037504]\n",
      " [0.2045089 ]\n",
      " [0.10553958]\n",
      " [0.10251562]\n",
      " [0.12463752]\n",
      " [0.10301082]\n",
      " [0.93416668]\n",
      " [0.1173775 ]\n",
      " [0.20563177]\n",
      " [0.10404072]\n",
      " [0.1009331 ]\n",
      " [0.10815042]\n",
      " [0.10081238]\n",
      " [0.10384432]\n",
      " [0.10744479]\n",
      " [0.10346799]\n",
      " [0.11310881]\n",
      " [0.1       ]\n",
      " [1.        ]\n",
      " [0.1057684 ]\n",
      " [0.19958738]\n",
      " [0.12145949]\n",
      " [0.17301211]\n",
      " [0.10325752]\n",
      " [0.10215258]\n",
      " [0.10002984]\n",
      " [0.19167453]\n",
      " [0.12145949]\n",
      " [0.11090459]\n",
      " [0.10346799]\n",
      " [0.12157743]\n",
      " [0.1010989 ]\n",
      " [0.10251562]\n",
      " [0.11806786]\n",
      " [0.10020275]\n",
      " [0.10596423]\n",
      " [0.10021308]\n",
      " [0.1       ]\n",
      " [0.10683302]\n",
      " [0.2045089 ]\n",
      " [0.10020275]\n",
      " [0.10376843]\n",
      " [0.10301082]\n",
      " [0.11921276]\n",
      " [0.14501813]\n",
      " [0.10251562]\n",
      " [0.10037504]\n",
      " [0.2490939 ]\n",
      " [0.16127638]\n",
      " [0.11633078]\n",
      " [0.14501813]\n",
      " [0.11833519]\n",
      " [0.10553958]\n",
      " [0.1023742 ]\n",
      " [0.10744479]\n",
      " [0.10902482]\n",
      " [0.10341163]\n",
      " [0.20563177]\n",
      " [0.11090459]\n",
      " [0.10051279]\n",
      " [0.17301211]\n",
      " [0.10136625]\n",
      " [0.10765307]\n",
      " [0.10136625]\n",
      " [0.1       ]] [[0.11833519]\n",
      " [0.2198164 ]\n",
      " [0.54100732]\n",
      " [0.10037504]\n",
      " [0.12145949]\n",
      " [0.10564562]\n",
      " [0.2198164 ]\n",
      " [0.10000001]\n",
      " [0.12744313]\n",
      " [0.10015133]\n",
      " [0.10423749]\n",
      " [0.19958738]\n",
      " [0.11921276]\n",
      " [0.10301082]\n",
      " [0.10021308]\n",
      " [0.11806786]\n",
      " [0.10020275]\n",
      " [0.10237092]\n",
      " [0.54100732]\n",
      " [0.10511731]\n",
      " [0.12463752]\n",
      " [0.12024153]\n",
      " [0.11966609]\n",
      " [0.10002154]\n",
      " [0.11729022]\n",
      " [0.10303275]\n",
      " [0.10020325]\n",
      " [0.10002984]\n",
      " [0.1010989 ]\n",
      " [0.11633078]\n",
      " [0.12364235]\n",
      " [0.10431081]\n",
      " [0.12463752]\n",
      " [0.10348193]\n",
      " [0.12024153]\n",
      " [0.11966609]\n",
      " [0.10511731]\n",
      " [0.10002984]\n",
      " [0.10051279]\n",
      " [0.10744479]\n",
      " [0.12744313]\n",
      " [0.11806786]\n",
      " [0.1238952 ]\n",
      " [1.        ]\n",
      " [0.11310881]\n",
      " [0.1238952 ]]\n",
      "True\n",
      "<keras.engine.sequential.Sequential object at 0x00000262FFF50278>\n",
      "{'proc': 3, 'K': 30, 'epochs': 1000, 'target': 'fco2', 'Save': {'Weights': True, 'Model': True}, 'Loss': 'Boot_Loss', 'Memory': 0.95, 'validation_split': 0.2, 'iteration': 1, 'Eval': True, 'Dpath': 'C:\\\\Users\\\\wesle\\\\NetworkAnalysis/Illisarvik/', 'Spath': 'C:\\\\Users\\\\wesle\\\\NetworkAnalysis/Illisarvik/ER/99_99/', 'Sname': 'Var', 'Inputs': ['PPFD_Avg', 'VPD', 'VWC', 'Shrub'], 'Model': 'PPFD_Avg+VPD+VWC+Shrub', 'N': 6, 'Validate': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\NetworkAnalysis\\DenseNet.py:144: RuntimeWarning: Mean of empty slice\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "121/121 [==============================] - 1s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: nan - val_loss: 317.8787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:543: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:436: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 1194.9008 - val_loss: 165.5497\n",
      "Epoch 4/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 651.7288 - val_loss: 117.8978\n",
      "Epoch 5/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: 487.9785 - val_loss: 94.6975\n",
      "Epoch 6/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 321.0035 - val_loss: 81.0666\n",
      "Epoch 7/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 296.3364 - val_loss: 72.1682\n",
      "Epoch 8/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: 277.8316 - val_loss: 65.9624\n",
      "Epoch 9/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 246.3311 - val_loss: 61.4367\n",
      "Epoch 10/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: 255.2271 - val_loss: 58.0258\n",
      "Epoch 11/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 248.2245 - val_loss: 55.3925\n",
      "Epoch 12/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: 226.0689 - val_loss: 53.3226\n",
      "Epoch 13/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 191.1718 - val_loss: 51.6714\n",
      "Epoch 14/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 216.3860 - val_loss: 50.3353\n",
      "Epoch 15/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 229.8971 - val_loss: 49.2429\n",
      "Epoch 16/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 188.7337 - val_loss: 48.3424\n",
      "Epoch 17/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 200.2032 - val_loss: 47.5921\n",
      "Epoch 18/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 216.4897 - val_loss: 46.9623\n",
      "Epoch 19/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 189.7172 - val_loss: 46.4277\n",
      "Epoch 20/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 176.6468 - val_loss: 45.9714\n",
      "Epoch 21/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 186.4039 - val_loss: 45.5798\n",
      "Epoch 22/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 200.5063 - val_loss: 45.2406\n",
      "Epoch 23/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: 192.5108 - val_loss: 44.9426\n",
      "Epoch 24/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 205.4036 - val_loss: 44.6810\n",
      "Epoch 25/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 193.0045 - val_loss: 44.4485\n",
      "Epoch 26/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 197.0508 - val_loss: 44.2391\n",
      "Epoch 27/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 191.6606 - val_loss: 44.0505\n",
      "Epoch 28/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 169.5292 - val_loss: 43.8771\n",
      "Epoch 29/1000\n",
      "121/121 [==============================] - ETA: 0s - loss: 211.750 - 0s 0us/step - loss: 180.9267 - val_loss: 43.7188\n",
      "Epoch 30/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 149.6360 - val_loss: 43.5715\n",
      "Epoch 31/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: 175.3903 - val_loss: 43.4320\n",
      "Epoch 32/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 177.2175 - val_loss: 43.2993\n",
      "Epoch 33/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 172.3351 - val_loss: 43.1719\n",
      "Epoch 34/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 166.1702 - val_loss: 43.0489\n",
      "Epoch 35/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 182.1468 - val_loss: 42.9300\n",
      "Epoch 36/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 177.6001 - val_loss: 42.8141\n",
      "Epoch 37/1000\n",
      "121/121 [==============================] - 0s 200us/step - loss: 165.7514 - val_loss: 42.7012\n",
      "Epoch 38/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 158.5434 - val_loss: 42.5912\n",
      "Epoch 39/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 161.0062 - val_loss: 42.4821\n",
      "Epoch 40/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 166.2749 - val_loss: 42.3748\n",
      "Epoch 41/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 154.9468 - val_loss: 42.2667\n",
      "Epoch 42/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 175.9745 - val_loss: 42.1609\n",
      "Epoch 43/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: 191.8497 - val_loss: 42.0557\n",
      "Epoch 44/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: 177.9020 - val_loss: 41.9518\n",
      "Epoch 45/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 173.1082 - val_loss: 41.8492\n",
      "Epoch 46/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: 168.0176 - val_loss: 41.7472\n",
      "Epoch 47/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: 165.4227 - val_loss: 41.6452\n",
      "Epoch 48/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: 165.6985 - val_loss: 41.5438\n",
      "Epoch 49/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 170.4429 - val_loss: 41.4414\n",
      "Epoch 50/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 154.8263 - val_loss: 41.3388\n",
      "Epoch 51/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 159.5742 - val_loss: 41.2360\n",
      "Epoch 52/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: 173.0818 - val_loss: 41.1318\n",
      "Epoch 53/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: 147.7335 - val_loss: 41.0284\n",
      "Epoch 54/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 154.9255 - val_loss: 40.9244\n",
      "Epoch 55/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 155.6702 - val_loss: 40.8109\n",
      "Epoch 56/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 171.9049 - val_loss: 40.6890\n",
      "Epoch 57/1000\n",
      "121/121 [==============================] - 0s 170us/step - loss: 161.6087 - val_loss: 40.5684\n",
      "Epoch 58/1000\n",
      "121/121 [==============================] - 0s 99us/step - loss: 152.9727 - val_loss: 40.4539\n",
      "Epoch 59/1000\n",
      "121/121 [==============================] - 0s 148us/step - loss: 156.1228 - val_loss: 40.3438\n",
      "Epoch 60/1000\n",
      "121/121 [==============================] - 0s 91us/step - loss: 151.2756 - val_loss: 40.2395\n",
      "Epoch 61/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 167.1594 - val_loss: 40.1395\n",
      "Epoch 62/1000\n",
      "121/121 [==============================] - 0s 91us/step - loss: 163.9210 - val_loss: 40.0416\n",
      "Epoch 63/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 134.3035 - val_loss: 39.9473\n",
      "Epoch 64/1000\n",
      "121/121 [==============================] - 0s 157us/step - loss: 147.4518 - val_loss: 39.8524\n",
      "Epoch 65/1000\n",
      "121/121 [==============================] - 0s 91us/step - loss: 153.2097 - val_loss: 39.7605\n",
      "Epoch 66/1000\n",
      "121/121 [==============================] - 0s 82us/step - loss: 161.8253 - val_loss: 39.6696\n",
      "Epoch 67/1000\n",
      "121/121 [==============================] - 0s 115us/step - loss: 123.2550 - val_loss: 39.5815\n",
      "Epoch 68/1000\n",
      "121/121 [==============================] - 0s 99us/step - loss: 174.6172 - val_loss: 39.4914\n",
      "Epoch 69/1000\n",
      "121/121 [==============================] - 0s 91us/step - loss: 143.1102 - val_loss: 39.4024\n",
      "Epoch 70/1000\n",
      "121/121 [==============================] - 0s 107us/step - loss: 159.8537 - val_loss: 39.3146\n",
      "Epoch 71/1000\n",
      "121/121 [==============================] - 0s 99us/step - loss: 138.3374 - val_loss: 39.2267\n",
      "Epoch 72/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: 156.3556 - val_loss: 39.1383\n",
      "Epoch 73/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: 144.4319 - val_loss: 39.0509\n",
      "Epoch 74/1000\n",
      "121/121 [==============================] - 0s 99us/step - loss: 147.3466 - val_loss: 38.9628\n",
      "Epoch 75/1000\n",
      "121/121 [==============================] - 0s 82us/step - loss: 122.7217 - val_loss: 38.0262\n",
      "Epoch 76/1000\n",
      "121/121 [==============================] - 0s 49us/step - loss: 141.2015 - val_loss: 36.4411\n",
      "Epoch 77/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 152.5502 - val_loss: 35.2434\n",
      "Epoch 78/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: 148.1253 - val_loss: 34.1411\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 74us/step - loss: 123.8991 - val_loss: 33.3255\n",
      "Epoch 80/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 132.6688 - val_loss: 32.7123\n",
      "Epoch 81/1000\n",
      "121/121 [==============================] - 0s 58us/step - loss: 112.0657 - val_loss: 32.2387\n",
      "Epoch 82/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: 124.9375 - val_loss: 31.8717\n",
      "Epoch 83/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: 154.1368 - val_loss: 31.5563\n",
      "Epoch 84/1000\n",
      "121/121 [==============================] - 0s 91us/step - loss: 122.8163 - val_loss: 31.2911\n",
      "Epoch 85/1000\n",
      "121/121 [==============================] - 0s 173us/step - loss: 144.5039 - val_loss: 31.0616\n",
      "Epoch 86/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: 114.6993 - val_loss: 30.8585\n",
      "Epoch 87/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 129.1189 - val_loss: 30.6750\n",
      "Epoch 88/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 142.1162 - val_loss: 30.5093\n",
      "Epoch 89/1000\n",
      "121/121 [==============================] - 0s 501us/step - loss: 132.6152 - val_loss: 30.3560\n",
      "Epoch 90/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 150.0201 - val_loss: 30.2126\n",
      "Epoch 91/1000\n",
      "121/121 [==============================] - 0s 200us/step - loss: 140.1631 - val_loss: 30.0775\n",
      "Epoch 92/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 145.0464 - val_loss: 29.9475\n",
      "Epoch 93/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 142.8221 - val_loss: 29.8240\n",
      "Epoch 94/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 131.5293 - val_loss: 29.7061\n",
      "Epoch 95/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 135.0458 - val_loss: 29.5921\n",
      "Epoch 96/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 124.2483 - val_loss: 29.4807\n",
      "Epoch 97/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 135.0972 - val_loss: 29.3722\n",
      "Epoch 98/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 135.0740 - val_loss: 29.2669\n",
      "Epoch 99/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 133.5825 - val_loss: 29.1621\n",
      "Epoch 100/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: 125.1862 - val_loss: 29.0593\n",
      "Epoch 101/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 129.4226 - val_loss: 28.9572\n",
      "Epoch 102/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 145.3727 - val_loss: 28.8556\n",
      "Epoch 103/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 130.3062 - val_loss: 28.7537\n",
      "Epoch 104/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 135.5705 - val_loss: 28.6536\n",
      "Epoch 105/1000\n",
      "121/121 [==============================] - 0s 137us/step - loss: 142.6398 - val_loss: 28.5546\n",
      "Epoch 106/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 144.4122 - val_loss: 28.4541\n",
      "Epoch 107/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 147.5001 - val_loss: 28.3554\n",
      "Epoch 108/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 134.1748 - val_loss: 28.2572\n",
      "Epoch 109/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 142.0021 - val_loss: 28.1583\n",
      "Epoch 110/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 113.0298 - val_loss: 28.0591\n",
      "Epoch 111/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: 136.8485 - val_loss: 27.9629\n",
      "Epoch 112/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 121.1496 - val_loss: 27.8654\n",
      "Epoch 113/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 145.4712 - val_loss: 27.7678\n",
      "Epoch 114/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 124.3554 - val_loss: 27.6716\n",
      "Epoch 115/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: 119.2659 - val_loss: 27.5759\n",
      "Epoch 116/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 125.6112 - val_loss: 27.4810\n",
      "Epoch 117/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 128.7238 - val_loss: 27.3858\n",
      "Epoch 118/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 130.6834 - val_loss: 27.2900\n",
      "Epoch 119/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 111.8267 - val_loss: 27.1949\n",
      "Epoch 120/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 118.4383 - val_loss: 27.0994\n",
      "Epoch 121/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: 119.3468 - val_loss: 27.0056\n",
      "Epoch 122/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 126.4911 - val_loss: 26.9123\n",
      "Epoch 123/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: 135.7049 - val_loss: 26.8191\n",
      "Epoch 124/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 133.1658 - val_loss: 26.7267\n",
      "Epoch 125/1000\n",
      "121/121 [==============================] - 0s 85us/step - loss: 133.3616 - val_loss: 26.6328\n",
      "Epoch 126/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: 114.0997 - val_loss: 26.5413\n",
      "Epoch 127/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 107.4956 - val_loss: 26.4261\n",
      "Epoch 128/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 127.2906 - val_loss: 26.2517\n",
      "Epoch 129/1000\n",
      "121/121 [==============================] - 0s 267us/step - loss: 115.3422 - val_loss: 26.0746\n",
      "Epoch 130/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 110.2401 - val_loss: 25.9125\n",
      "Epoch 131/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: 107.4502 - val_loss: 25.7688\n",
      "Epoch 132/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 99.8749 - val_loss: 25.6413\n",
      "Epoch 133/1000\n",
      "121/121 [==============================] - 0s 68us/step - loss: 95.4490 - val_loss: 25.5263\n",
      "Epoch 134/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 108.4033 - val_loss: 25.4201\n",
      "Epoch 135/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: 90.4146 - val_loss: 25.3200\n",
      "Epoch 136/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 102.6214 - val_loss: 25.2240\n",
      "Epoch 137/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 90.3444 - val_loss: 25.1312\n",
      "Epoch 138/1000\n",
      "121/121 [==============================] - ETA: 0s - loss: 110.995 - 0s 0us/step - loss: 94.8975 - val_loss: 25.0405\n",
      "Epoch 139/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: 93.9520 - val_loss: 24.9524\n",
      "Epoch 140/1000\n",
      "121/121 [==============================] - 0s 91us/step - loss: 88.9764 - val_loss: 24.8671\n",
      "Epoch 141/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: 101.0566 - val_loss: 24.7826\n",
      "Epoch 142/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 98.6748 - val_loss: 24.7005\n",
      "Epoch 143/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 86.4640 - val_loss: 24.6189\n",
      "Epoch 144/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 88.2563 - val_loss: 24.5382\n",
      "Epoch 145/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 87.6938 - val_loss: 24.4595\n",
      "Epoch 146/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 92.5654 - val_loss: 24.3811\n",
      "Epoch 147/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 82.0976 - val_loss: 24.3038\n",
      "Epoch 148/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: 72.1059 - val_loss: 24.2279\n",
      "Epoch 149/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: 82.6360 - val_loss: 24.1522\n",
      "Epoch 150/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 75.9946 - val_loss: 24.0758\n",
      "Epoch 151/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: 97.3831 - val_loss: 23.9990\n",
      "Epoch 152/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 96.8444 - val_loss: 23.9219\n",
      "Epoch 153/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: 85.5930 - val_loss: 23.8456\n",
      "Epoch 154/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 95.4949 - val_loss: 23.7563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 61.7746 - val_loss: 23.6703\n",
      "Epoch 156/1000\n",
      "121/121 [==============================] - 0s 70us/step - loss: 72.7710 - val_loss: 23.5856\n",
      "Epoch 157/1000\n",
      "121/121 [==============================] - ETA: 0s - loss: 101.054 - 0s 129us/step - loss: 83.5297 - val_loss: 23.5044\n",
      "Epoch 158/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 74.4738 - val_loss: 23.4184\n",
      "Epoch 159/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 73.5574 - val_loss: 23.3349\n",
      "Epoch 160/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: 75.6486 - val_loss: 23.2533\n",
      "Epoch 161/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 63.2946 - val_loss: 23.1183\n",
      "Epoch 162/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: 66.1468 - val_loss: 22.5987\n",
      "Epoch 163/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: 70.6042 - val_loss: 22.1158\n",
      "Epoch 164/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 54.6789 - val_loss: 21.6701\n",
      "Epoch 165/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 46.6172 - val_loss: 21.2548\n",
      "Epoch 166/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: 63.5126 - val_loss: 20.8751\n",
      "Epoch 167/1000\n",
      "121/121 [==============================] - 0s 71us/step - loss: 61.9421 - val_loss: 20.5252\n",
      "Epoch 168/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 67.6792 - val_loss: 20.2102\n",
      "Epoch 169/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 62.9444 - val_loss: 19.9199\n",
      "Epoch 170/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: 57.2799 - val_loss: 19.6441\n",
      "Epoch 171/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 59.4724 - val_loss: 19.3845\n",
      "Epoch 172/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 76.9005 - val_loss: 19.1446\n",
      "Epoch 173/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: 51.7689 - val_loss: 18.9214\n",
      "Epoch 174/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: 64.5984 - val_loss: 18.7103\n",
      "Epoch 175/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: 75.2978 - val_loss: 18.5112\n",
      "Epoch 176/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: 43.1667 - val_loss: 18.3253\n",
      "Epoch 177/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: 68.6717 - val_loss: 18.1475\n",
      "Epoch 178/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 51.5492 - val_loss: 17.9791\n",
      "Epoch 179/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: 58.7108 - val_loss: 17.8198\n",
      "Epoch 180/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 57.8172 - val_loss: 17.6691\n",
      "Epoch 181/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 52.2450 - val_loss: 17.5235\n",
      "Epoch 182/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 59.4898 - val_loss: 17.3861\n",
      "Epoch 183/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 69.0196 - val_loss: 17.2541\n",
      "Epoch 184/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 54.5615 - val_loss: 17.1227\n",
      "Epoch 185/1000\n",
      "121/121 [==============================] - 0s 82us/step - loss: 63.4066 - val_loss: 16.9918\n",
      "Epoch 186/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: 62.4648 - val_loss: 16.8634\n",
      "Epoch 187/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: 55.2838 - val_loss: 16.7411\n",
      "Epoch 188/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 71.9531 - val_loss: 16.6210\n",
      "Epoch 189/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 47.9929 - val_loss: 16.4988\n",
      "Epoch 190/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 51.5417 - val_loss: 16.3767\n",
      "Epoch 191/1000\n",
      "121/121 [==============================] - 0s 259us/step - loss: 65.6418 - val_loss: 16.2574\n",
      "Epoch 192/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 52.4501 - val_loss: 16.1401\n",
      "Epoch 193/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 66.4344 - val_loss: 16.0240\n",
      "Epoch 194/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 53.1034 - val_loss: 15.9103\n",
      "Epoch 195/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 67.2527 - val_loss: 15.7979\n",
      "Epoch 196/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 59.8925 - val_loss: 15.6905\n",
      "Epoch 197/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 44.9911 - val_loss: 15.5884\n",
      "Epoch 198/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 60.0869 - val_loss: 15.4935\n",
      "Epoch 199/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 59.6848 - val_loss: 15.4009\n",
      "Epoch 200/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 65.5058 - val_loss: 15.3113\n",
      "Epoch 201/1000\n",
      "121/121 [==============================] - 0s 271us/step - loss: 55.4908 - val_loss: 15.2226\n",
      "Epoch 202/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 40.3493 - val_loss: 15.1359\n",
      "Epoch 203/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 63.6054 - val_loss: 15.0507\n",
      "Epoch 204/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 51.4157 - val_loss: 14.6565\n",
      "Epoch 205/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 57.0125 - val_loss: 12.4619\n",
      "Epoch 206/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 57.4039 - val_loss: 10.2557\n",
      "Epoch 207/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: 47.2574 - val_loss: 8.5093\n",
      "Epoch 208/1000\n",
      "121/121 [==============================] - ETA: 0s - loss: 65.59 - 0s 0us/step - loss: 55.4685 - val_loss: 7.2091\n",
      "Epoch 209/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 58.8548 - val_loss: 4.2789\n",
      "Epoch 210/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: 49.8831 - val_loss: 0.1786\n",
      "Epoch 211/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 15.5790 - val_loss: -2.3769\n",
      "Epoch 212/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: 5.0834 - val_loss: -7.4662\n",
      "Epoch 213/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -10.8342 - val_loss: -10.0272\n",
      "Epoch 214/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -20.6813 - val_loss: -11.3078\n",
      "Epoch 215/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -26.8582 - val_loss: -12.0234\n",
      "Epoch 216/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -31.3684 - val_loss: -12.4781\n",
      "Epoch 217/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -31.2494 - val_loss: -12.7851\n",
      "Epoch 218/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -33.0856 - val_loss: -12.9989\n",
      "Epoch 219/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -33.9174 - val_loss: -13.1545\n",
      "Epoch 220/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -36.4310 - val_loss: -13.2706\n",
      "Epoch 221/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -34.8493 - val_loss: -13.3600\n",
      "Epoch 222/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -35.0938 - val_loss: -13.4403\n",
      "Epoch 223/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -35.0536 - val_loss: -13.5058\n",
      "Epoch 224/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -35.0002 - val_loss: -13.5598\n",
      "Epoch 225/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -35.6040 - val_loss: -13.6059\n",
      "Epoch 226/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -35.9083 - val_loss: -13.6458\n",
      "Epoch 227/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -35.9346 - val_loss: -13.6790\n",
      "Epoch 228/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -36.1196 - val_loss: -13.7090\n",
      "Epoch 229/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -36.2735 - val_loss: -13.7365\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 129us/step - loss: -36.6957 - val_loss: -13.7619\n",
      "Epoch 231/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.8617 - val_loss: -13.7860\n",
      "Epoch 232/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -36.4647 - val_loss: -13.8083\n",
      "Epoch 233/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -36.8215 - val_loss: -13.8282\n",
      "Epoch 234/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -36.2405 - val_loss: -13.8469\n",
      "Epoch 235/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -35.7220 - val_loss: -13.8648\n",
      "Epoch 236/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -37.9127 - val_loss: -13.8826\n",
      "Epoch 237/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.0772 - val_loss: -13.9000\n",
      "Epoch 238/1000\n",
      "121/121 [==============================] - 0s 312us/step - loss: -37.3239 - val_loss: -13.9163\n",
      "Epoch 239/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -36.4046 - val_loss: -13.9322\n",
      "Epoch 240/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -37.4926 - val_loss: -13.9481\n",
      "Epoch 241/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -37.0603 - val_loss: -13.9635\n",
      "Epoch 242/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -36.2474 - val_loss: -13.9786\n",
      "Epoch 243/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.4756 - val_loss: -13.9937\n",
      "Epoch 244/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.3024 - val_loss: -14.0084\n",
      "Epoch 245/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.1465 - val_loss: -14.0233\n",
      "Epoch 246/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -37.5621 - val_loss: -14.0378\n",
      "Epoch 247/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -37.0424 - val_loss: -14.0524\n",
      "Epoch 248/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -36.4288 - val_loss: -14.0666\n",
      "Epoch 249/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -36.9408 - val_loss: -14.0806\n",
      "Epoch 250/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -40.1933 - val_loss: -14.0949\n",
      "Epoch 251/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -37.4128 - val_loss: -14.1082\n",
      "Epoch 252/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -37.0868 - val_loss: -14.1215\n",
      "Epoch 253/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -36.9317 - val_loss: -14.1343\n",
      "Epoch 254/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.1644 - val_loss: -14.1467\n",
      "Epoch 255/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.6526 - val_loss: -14.1594\n",
      "Epoch 256/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.3454 - val_loss: -14.1719\n",
      "Epoch 257/1000\n",
      "121/121 [==============================] - ETA: 0s - loss: -43.977 - 0s 0us/step - loss: -37.9724 - val_loss: -14.1839\n",
      "Epoch 258/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -40.0378 - val_loss: -14.1956\n",
      "Epoch 259/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -38.7398 - val_loss: -14.2072\n",
      "Epoch 260/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.0361 - val_loss: -14.2188\n",
      "Epoch 261/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.2495 - val_loss: -14.2299\n",
      "Epoch 262/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.0435 - val_loss: -14.2408\n",
      "Epoch 263/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.5541 - val_loss: -14.2515\n",
      "Epoch 264/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.4051 - val_loss: -14.2627\n",
      "Epoch 265/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.7712 - val_loss: -14.2731\n",
      "Epoch 266/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.9643 - val_loss: -14.2834\n",
      "Epoch 267/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.4498 - val_loss: -14.2939\n",
      "Epoch 268/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.4766 - val_loss: -14.3039\n",
      "Epoch 269/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.5944 - val_loss: -14.3134\n",
      "Epoch 270/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -37.1856 - val_loss: -14.3225\n",
      "Epoch 271/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.8345 - val_loss: -14.3322\n",
      "Epoch 272/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.0541 - val_loss: -14.3415\n",
      "Epoch 273/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.3558 - val_loss: -14.3509\n",
      "Epoch 274/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -37.9790 - val_loss: -14.3599\n",
      "Epoch 275/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.0890 - val_loss: -14.3687\n",
      "Epoch 276/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -39.2849 - val_loss: -14.3777\n",
      "Epoch 277/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.7136 - val_loss: -14.3869\n",
      "Epoch 278/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.1094 - val_loss: -14.3957\n",
      "Epoch 279/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.4903 - val_loss: -14.4042\n",
      "Epoch 280/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.7651 - val_loss: -14.4126\n",
      "Epoch 281/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -37.7669 - val_loss: -14.4209\n",
      "Epoch 282/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.8985 - val_loss: -14.4291\n",
      "Epoch 283/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -38.7917 - val_loss: -14.4371\n",
      "Epoch 284/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.2718 - val_loss: -14.4452\n",
      "Epoch 285/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.8180 - val_loss: -14.4532\n",
      "Epoch 286/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.2664 - val_loss: -14.4610\n",
      "Epoch 287/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -37.7615 - val_loss: -14.4682\n",
      "Epoch 288/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -37.7797 - val_loss: -14.4753\n",
      "Epoch 289/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.2863 - val_loss: -14.4823\n",
      "Epoch 290/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.8635 - val_loss: -14.4897\n",
      "Epoch 291/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -38.4891 - val_loss: -14.4967\n",
      "Epoch 292/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.6756 - val_loss: -14.5040\n",
      "Epoch 293/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.8315 - val_loss: -14.5119\n",
      "Epoch 294/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -39.8330 - val_loss: -14.5212\n",
      "Epoch 295/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.1655 - val_loss: -14.5300\n",
      "Epoch 296/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.1656 - val_loss: -14.5386\n",
      "Epoch 297/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.8083 - val_loss: -14.5474\n",
      "Epoch 298/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.9951 - val_loss: -14.5560\n",
      "Epoch 299/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.1833 - val_loss: -14.5641\n",
      "Epoch 300/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.3017 - val_loss: -14.5728\n",
      "Epoch 301/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.0009 - val_loss: -14.5810\n",
      "Epoch 302/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -38.7396 - val_loss: -14.5886\n",
      "Epoch 303/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.6056 - val_loss: -14.5961\n",
      "Epoch 304/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.0800 - val_loss: -14.6031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.5881 - val_loss: -14.6107\n",
      "Epoch 306/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.9700 - val_loss: -14.6179\n",
      "Epoch 307/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.9179 - val_loss: -14.6249\n",
      "Epoch 308/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.6700 - val_loss: -14.6322\n",
      "Epoch 309/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -39.4208 - val_loss: -14.6393\n",
      "Epoch 310/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3997 - val_loss: -14.6464\n",
      "Epoch 311/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.8125 - val_loss: -14.6537\n",
      "Epoch 312/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -38.9293 - val_loss: -14.6612\n",
      "Epoch 313/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.6498 - val_loss: -14.6692\n",
      "Epoch 314/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.8290 - val_loss: -14.6771\n",
      "Epoch 315/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.7501 - val_loss: -14.6845\n",
      "Epoch 316/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.6326 - val_loss: -14.6926\n",
      "Epoch 317/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.5551 - val_loss: -14.7006\n",
      "Epoch 318/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -39.0749 - val_loss: -14.7080\n",
      "Epoch 319/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -38.3613 - val_loss: -14.7156\n",
      "Epoch 320/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.0043 - val_loss: -14.7235\n",
      "Epoch 321/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -40.4613 - val_loss: -14.7314\n",
      "Epoch 322/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -38.8969 - val_loss: -14.7389\n",
      "Epoch 323/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -38.9584 - val_loss: -14.7462\n",
      "Epoch 324/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -41.4969 - val_loss: -14.7546\n",
      "Epoch 325/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.5944 - val_loss: -14.7622\n",
      "Epoch 326/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.4513 - val_loss: -14.7702\n",
      "Epoch 327/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -39.6736 - val_loss: -14.7777\n",
      "Epoch 328/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -38.5927 - val_loss: -14.7852\n",
      "Epoch 329/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.2719 - val_loss: -14.7929\n",
      "Epoch 330/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.9977 - val_loss: -14.8007\n",
      "Epoch 331/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.2084 - val_loss: -14.8080\n",
      "Epoch 332/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.0137 - val_loss: -14.8156\n",
      "Epoch 333/1000\n",
      "121/121 [==============================] - 0s 58us/step - loss: -38.8665 - val_loss: -14.8227\n",
      "Epoch 334/1000\n",
      "121/121 [==============================] - 0s 132us/step - loss: -40.2277 - val_loss: -14.8301\n",
      "Epoch 335/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -38.8414 - val_loss: -14.8373\n",
      "Epoch 336/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -38.8212 - val_loss: -14.8442\n",
      "Epoch 337/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.1766 - val_loss: -14.8512\n",
      "Epoch 338/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.9726 - val_loss: -14.8588\n",
      "Epoch 339/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.7047 - val_loss: -14.8661\n",
      "Epoch 340/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.3229 - val_loss: -14.8729\n",
      "Epoch 341/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3626 - val_loss: -14.8797\n",
      "Epoch 342/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.0224 - val_loss: -14.8864\n",
      "Epoch 343/1000\n",
      "121/121 [==============================] - 0s 387us/step - loss: -40.7341 - val_loss: -14.8935\n",
      "Epoch 344/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.0118 - val_loss: -14.8998\n",
      "Epoch 345/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.8437 - val_loss: -14.9066\n",
      "Epoch 346/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -39.6037 - val_loss: -14.9130\n",
      "Epoch 347/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.7419 - val_loss: -14.9193\n",
      "Epoch 348/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -40.1206 - val_loss: -14.9256\n",
      "Epoch 349/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.7543 - val_loss: -14.9325\n",
      "Epoch 350/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.5090 - val_loss: -14.9386\n",
      "Epoch 351/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.4388 - val_loss: -14.9449\n",
      "Epoch 352/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.1709 - val_loss: -14.9510\n",
      "Epoch 353/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.4360 - val_loss: -14.9572\n",
      "Epoch 354/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3190 - val_loss: -14.9632\n",
      "Epoch 355/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: -40.0717 - val_loss: -14.9685\n",
      "Epoch 356/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -39.2060 - val_loss: -14.9738\n",
      "Epoch 357/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -39.2398 - val_loss: -14.9793\n",
      "Epoch 358/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3384 - val_loss: -14.9853\n",
      "Epoch 359/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: -40.3975 - val_loss: -14.9907\n",
      "Epoch 360/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.1594 - val_loss: -14.9959\n",
      "Epoch 361/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -39.9809 - val_loss: -15.0011\n",
      "Epoch 362/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.9335 - val_loss: -15.0065\n",
      "Epoch 363/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.9027 - val_loss: -15.0117\n",
      "Epoch 364/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.1432 - val_loss: -15.0176\n",
      "Epoch 365/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.4661 - val_loss: -15.0227\n",
      "Epoch 366/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -42.3779 - val_loss: -15.0285\n",
      "Epoch 367/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.6457 - val_loss: -15.0334\n",
      "Epoch 368/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.6108 - val_loss: -15.0385\n",
      "Epoch 369/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.1060 - val_loss: -15.0434\n",
      "Epoch 370/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.7054 - val_loss: -15.0487\n",
      "Epoch 371/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.5892 - val_loss: -15.0534\n",
      "Epoch 372/1000\n",
      "121/121 [==============================] - 0s 264us/step - loss: -40.9197 - val_loss: -15.0586\n",
      "Epoch 373/1000\n",
      "121/121 [==============================] - 0s 288us/step - loss: -40.6740 - val_loss: -15.0635\n",
      "Epoch 374/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: -39.4948 - val_loss: -15.0683\n",
      "Epoch 375/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3905 - val_loss: -15.0732\n",
      "Epoch 376/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.6352 - val_loss: -15.0776\n",
      "Epoch 377/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.3326 - val_loss: -15.0828\n",
      "Epoch 378/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.7685 - val_loss: -15.0876\n",
      "Epoch 379/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.3306 - val_loss: -15.0926\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 129us/step - loss: -40.8254 - val_loss: -15.0969\n",
      "Epoch 381/1000\n",
      "121/121 [==============================] - 0s 173us/step - loss: -41.9429 - val_loss: -15.1019\n",
      "Epoch 382/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.4238 - val_loss: -15.1069\n",
      "Epoch 383/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.4223 - val_loss: -15.1114\n",
      "Epoch 384/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.3775 - val_loss: -15.1161\n",
      "Epoch 385/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -43.4375 - val_loss: -15.1215\n",
      "Epoch 386/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.2474 - val_loss: -15.1259\n",
      "Epoch 387/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.2100 - val_loss: -15.1300\n",
      "Epoch 388/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.4358 - val_loss: -15.1340\n",
      "Epoch 389/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.6360 - val_loss: -15.1382\n",
      "Epoch 390/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.1565 - val_loss: -15.1424\n",
      "Epoch 391/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -41.2008 - val_loss: -15.1469\n",
      "Epoch 392/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.6566 - val_loss: -15.1509\n",
      "Epoch 393/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.8399 - val_loss: -15.1558\n",
      "Epoch 394/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.4445 - val_loss: -15.1600\n",
      "Epoch 395/1000\n",
      "121/121 [==============================] - 0s 112us/step - loss: -39.6235 - val_loss: -15.1639\n",
      "Epoch 396/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.2805 - val_loss: -15.1682\n",
      "Epoch 397/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.3745 - val_loss: -15.1722\n",
      "Epoch 398/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.1666 - val_loss: -15.1762\n",
      "Epoch 399/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.3583 - val_loss: -15.1802\n",
      "Epoch 400/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -40.5393 - val_loss: -15.1846\n",
      "Epoch 401/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.2698 - val_loss: -15.1893\n",
      "Epoch 402/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.3877 - val_loss: -15.1934\n",
      "Epoch 403/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.1108 - val_loss: -15.1974\n",
      "Epoch 404/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3489 - val_loss: -15.2016\n",
      "Epoch 405/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.6543 - val_loss: -15.2056\n",
      "Epoch 406/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.8281 - val_loss: -15.2093\n",
      "Epoch 407/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3753 - val_loss: -15.2134\n",
      "Epoch 408/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.2505 - val_loss: -15.2174\n",
      "Epoch 409/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.5757 - val_loss: -15.2217\n",
      "Epoch 410/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.9354 - val_loss: -15.2254\n",
      "Epoch 411/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.7326 - val_loss: -15.2290\n",
      "Epoch 412/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.5497 - val_loss: -15.2326\n",
      "Epoch 413/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.8478 - val_loss: -15.2361\n",
      "Epoch 414/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.3527 - val_loss: -15.2402\n",
      "Epoch 415/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.4429 - val_loss: -15.2434\n",
      "Epoch 416/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.6808 - val_loss: -15.2473\n",
      "Epoch 417/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -40.4359 - val_loss: -15.2505\n",
      "Epoch 418/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.7789 - val_loss: -15.2546\n",
      "Epoch 419/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: -39.7815 - val_loss: -15.2581\n",
      "Epoch 420/1000\n",
      "121/121 [==============================] - 0s 134us/step - loss: -40.6271 - val_loss: -15.2618\n",
      "Epoch 421/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.3318 - val_loss: -15.2654\n",
      "Epoch 422/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -42.7508 - val_loss: -15.2694\n",
      "Epoch 423/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.6296 - val_loss: -15.2733\n",
      "Epoch 424/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -40.7823 - val_loss: -15.2765\n",
      "Epoch 425/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -43.5221 - val_loss: -15.2805\n",
      "Epoch 426/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.3743 - val_loss: -15.2840\n",
      "Epoch 427/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.5692 - val_loss: -15.2873\n",
      "Epoch 428/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3187 - val_loss: -15.2906\n",
      "Epoch 429/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.4179 - val_loss: -15.2936\n",
      "Epoch 430/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.7213 - val_loss: -15.2968\n",
      "Epoch 431/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.1125 - val_loss: -15.2996\n",
      "Epoch 432/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.0690 - val_loss: -15.3022\n",
      "Epoch 433/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.6166 - val_loss: -15.3054\n",
      "Epoch 434/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.2181 - val_loss: -15.3077\n",
      "Epoch 435/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.6203 - val_loss: -15.3109\n",
      "Epoch 436/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.6698 - val_loss: -15.3135\n",
      "Epoch 437/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.4301 - val_loss: -15.3156\n",
      "Epoch 438/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.6739 - val_loss: -15.3179\n",
      "Epoch 439/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.2515 - val_loss: -15.3204\n",
      "Epoch 440/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -42.7332 - val_loss: -15.3233\n",
      "Epoch 441/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.9602 - val_loss: -15.3253\n",
      "Epoch 442/1000\n",
      "121/121 [==============================] - 0s 312us/step - loss: -40.0983 - val_loss: -15.3274\n",
      "Epoch 443/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.5624 - val_loss: -15.3299\n",
      "Epoch 444/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -40.9378 - val_loss: -15.3322\n",
      "Epoch 445/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.5052 - val_loss: -15.3349\n",
      "Epoch 446/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -41.0212 - val_loss: -15.3372\n",
      "Epoch 447/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.1297 - val_loss: -15.3390\n",
      "Epoch 448/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.6501 - val_loss: -15.3409\n",
      "Epoch 449/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.7289 - val_loss: -15.3437\n",
      "Epoch 450/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.8821 - val_loss: -15.3457\n",
      "Epoch 451/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.1658 - val_loss: -15.3482\n",
      "Epoch 452/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.4775 - val_loss: -15.3507\n",
      "Epoch 453/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.8264 - val_loss: -15.3524\n",
      "Epoch 454/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -40.0372 - val_loss: -15.3539\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 0us/step - loss: -39.8984 - val_loss: -15.3556\n",
      "Epoch 456/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -41.1331 - val_loss: -15.3582\n",
      "Epoch 457/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.7139 - val_loss: -15.3602\n",
      "Epoch 458/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -40.6958 - val_loss: -15.3622\n",
      "Epoch 459/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.2392 - val_loss: -15.3642\n",
      "Epoch 460/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.9132 - val_loss: -15.3664\n",
      "Epoch 461/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.9713 - val_loss: -15.3687\n",
      "Epoch 462/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.5726 - val_loss: -15.3711\n",
      "Epoch 463/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -42.6681 - val_loss: -15.3739\n",
      "Epoch 464/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.5108 - val_loss: -15.3762\n",
      "Epoch 465/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.1740 - val_loss: -15.3781\n",
      "Epoch 466/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -40.0552 - val_loss: -15.3800\n",
      "Epoch 467/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.2736 - val_loss: -15.3818\n",
      "Epoch 468/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.6539 - val_loss: -15.3844\n",
      "Epoch 469/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -43.5660 - val_loss: -15.3877\n",
      "Epoch 470/1000\n",
      "121/121 [==============================] - ETA: 0s - loss: -45.793 - 0s 0us/step - loss: -39.9108 - val_loss: -15.3889\n",
      "Epoch 471/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.1985 - val_loss: -15.3904\n",
      "Epoch 472/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.8907 - val_loss: -15.3922\n",
      "Epoch 473/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.7022 - val_loss: -15.3941\n",
      "Epoch 474/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.9381 - val_loss: -15.3960\n",
      "Epoch 475/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.5597 - val_loss: -15.3977\n",
      "Epoch 476/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3358 - val_loss: -15.3993\n",
      "Epoch 477/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -43.3510 - val_loss: -15.4022\n",
      "Epoch 478/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.5659 - val_loss: -15.4040\n",
      "Epoch 479/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.6337 - val_loss: -15.4052\n",
      "Epoch 480/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.2693 - val_loss: -15.4066\n",
      "Epoch 481/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.7592 - val_loss: -15.4086\n",
      "Epoch 482/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.3454 - val_loss: -15.4100\n",
      "Epoch 483/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -39.9151 - val_loss: -15.4116\n",
      "Epoch 484/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.4748 - val_loss: -15.4138\n",
      "Epoch 485/1000\n",
      "121/121 [==============================] - 0s 54us/step - loss: -41.0147 - val_loss: -15.4155\n",
      "Epoch 486/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.4858 - val_loss: -15.4172\n",
      "Epoch 487/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -42.4258 - val_loss: -15.4196\n",
      "Epoch 488/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.0598 - val_loss: -15.4208\n",
      "Epoch 489/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.8061 - val_loss: -15.4222\n",
      "Epoch 490/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.5746 - val_loss: -15.4237\n",
      "Epoch 491/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.1690 - val_loss: -15.4254\n",
      "Epoch 492/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -42.5011 - val_loss: -15.4277\n",
      "Epoch 493/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -41.1110 - val_loss: -15.4289\n",
      "Epoch 494/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -39.6455 - val_loss: -15.4299\n",
      "Epoch 495/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.0055 - val_loss: -15.4316\n",
      "Epoch 496/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.7309 - val_loss: -15.4335\n",
      "Epoch 497/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -43.2685 - val_loss: -15.4358\n",
      "Epoch 498/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -42.1634 - val_loss: -15.4375\n",
      "Epoch 499/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.7654 - val_loss: -15.4388\n",
      "Epoch 500/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.5152 - val_loss: -15.4404\n",
      "Epoch 501/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.3227 - val_loss: -15.4416\n",
      "Epoch 502/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.4343 - val_loss: -15.4427\n",
      "Epoch 503/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.7521 - val_loss: -15.4437\n",
      "Epoch 504/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.5159 - val_loss: -15.4447\n",
      "Epoch 505/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -40.2216 - val_loss: -15.4458\n",
      "Epoch 506/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -42.1272 - val_loss: -15.4477\n",
      "Epoch 507/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.5050 - val_loss: -15.4497\n",
      "Epoch 508/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -40.8242 - val_loss: -15.4509\n",
      "Epoch 509/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.9327 - val_loss: -15.4518\n",
      "Epoch 510/1000\n",
      "121/121 [==============================] - 0s 258us/step - loss: -40.8354 - val_loss: -15.4530\n",
      "Epoch 511/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.5902 - val_loss: -15.4541\n",
      "Epoch 512/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -41.2829 - val_loss: -15.4553\n",
      "Epoch 513/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -39.9589 - val_loss: -15.4562\n",
      "Epoch 514/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.1342 - val_loss: -15.4575\n",
      "Epoch 515/1000\n",
      "121/121 [==============================] - 0s 312us/step - loss: -41.0751 - val_loss: -15.4590\n",
      "Epoch 516/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.3453 - val_loss: -15.4600\n",
      "Epoch 517/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -41.1268 - val_loss: -15.4616\n",
      "Epoch 518/1000\n",
      "121/121 [==============================] - 0s 71us/step - loss: -42.1839 - val_loss: -15.4640\n",
      "Epoch 519/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -40.9740 - val_loss: -15.4649\n",
      "Epoch 520/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4693 - val_loss: -15.4664\n",
      "Epoch 521/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.4547 - val_loss: -15.4685\n",
      "Epoch 522/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.9854 - val_loss: -15.4700\n",
      "Epoch 523/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.1719 - val_loss: -15.4718\n",
      "Epoch 524/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.1692 - val_loss: -15.4729\n",
      "Epoch 525/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -41.4046 - val_loss: -15.4737\n",
      "Epoch 526/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4473 - val_loss: -15.4748\n",
      "Epoch 527/1000\n",
      "121/121 [==============================] - 0s 433us/step - loss: -40.5528 - val_loss: -15.4757\n",
      "Epoch 528/1000\n",
      "121/121 [==============================] - 0s 233us/step - loss: -41.0596 - val_loss: -15.4766\n",
      "Epoch 529/1000\n",
      "121/121 [==============================] - 0s 152us/step - loss: -40.2804 - val_loss: -15.4778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/1000\n",
      "121/121 [==============================] - 0s 251us/step - loss: -41.0240 - val_loss: -15.4791\n",
      "Epoch 531/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.0726 - val_loss: -15.4801\n",
      "Epoch 532/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4663 - val_loss: -15.4821\n",
      "Epoch 533/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -40.4518 - val_loss: -15.4830\n",
      "Epoch 534/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4111 - val_loss: -15.4843\n",
      "Epoch 535/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -40.1897 - val_loss: -15.4851\n",
      "Epoch 536/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: -41.0162 - val_loss: -15.4861\n",
      "Epoch 537/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -41.8813 - val_loss: -15.4875\n",
      "Epoch 538/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8378 - val_loss: -15.4889\n",
      "Epoch 539/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3485 - val_loss: -15.4902\n",
      "Epoch 540/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.5892 - val_loss: -15.4921\n",
      "Epoch 541/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.9305 - val_loss: -15.4947\n",
      "Epoch 542/1000\n",
      "121/121 [==============================] - 0s 317us/step - loss: -42.4642 - val_loss: -15.4960\n",
      "Epoch 543/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -40.5755 - val_loss: -15.4963\n",
      "Epoch 544/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -41.0952 - val_loss: -15.4966\n",
      "Epoch 545/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.5903 - val_loss: -15.4983\n",
      "Epoch 546/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8844 - val_loss: -15.4992\n",
      "Epoch 547/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.4633 - val_loss: -15.5001\n",
      "Epoch 548/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -42.2514 - val_loss: -15.5015\n",
      "Epoch 549/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3734 - val_loss: -15.5025\n",
      "Epoch 550/1000\n",
      "121/121 [==============================] - 0s 266us/step - loss: -41.2355 - val_loss: -15.5033\n",
      "Epoch 551/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.8805 - val_loss: -15.5056\n",
      "Epoch 552/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.9489 - val_loss: -15.5066\n",
      "Epoch 553/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -42.8963 - val_loss: -15.5081\n",
      "Epoch 554/1000\n",
      "121/121 [==============================] - 0s 168us/step - loss: -41.5699 - val_loss: -15.5081\n",
      "Epoch 555/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.2225 - val_loss: -15.5079\n",
      "Epoch 556/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -42.9299 - val_loss: -15.5089\n",
      "Epoch 557/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3386 - val_loss: -15.5091\n",
      "Epoch 558/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.8301 - val_loss: -15.5102\n",
      "Epoch 559/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8652 - val_loss: -15.5109\n",
      "Epoch 560/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.2692 - val_loss: -15.5116\n",
      "Epoch 561/1000\n",
      "121/121 [==============================] - 0s 74us/step - loss: -41.8116 - val_loss: -15.5126\n",
      "Epoch 562/1000\n",
      "121/121 [==============================] - 0s 293us/step - loss: -42.3277 - val_loss: -15.5143\n",
      "Epoch 563/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.1978 - val_loss: -15.5144\n",
      "Epoch 564/1000\n",
      "121/121 [==============================] - 0s 401us/step - loss: -41.4262 - val_loss: -15.5155\n",
      "Epoch 565/1000\n",
      "121/121 [==============================] - 0s 483us/step - loss: -41.7169 - val_loss: -15.5162\n",
      "Epoch 566/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.5786 - val_loss: -15.5168\n",
      "Epoch 567/1000\n",
      "121/121 [==============================] - 0s 333us/step - loss: -40.3974 - val_loss: -15.5175\n",
      "Epoch 568/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: -41.2634 - val_loss: -15.5188\n",
      "Epoch 569/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -42.7412 - val_loss: -15.5207\n",
      "Epoch 570/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -41.1165 - val_loss: -15.5215\n",
      "Epoch 571/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.6732 - val_loss: -15.5234\n",
      "Epoch 572/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.8371 - val_loss: -15.5253\n",
      "Epoch 573/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.4336 - val_loss: -15.5255\n",
      "Epoch 574/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.6539 - val_loss: -15.5261\n",
      "Epoch 575/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -41.3332 - val_loss: -15.5270\n",
      "Epoch 576/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.7045 - val_loss: -15.5284\n",
      "Epoch 577/1000\n",
      "121/121 [==============================] - 0s 148us/step - loss: -41.2361 - val_loss: -15.5290\n",
      "Epoch 578/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.8955 - val_loss: -15.5294\n",
      "Epoch 579/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -41.3782 - val_loss: -15.5300\n",
      "Epoch 580/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -41.4825 - val_loss: -15.5313\n",
      "Epoch 581/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -40.7948 - val_loss: -15.5318\n",
      "Epoch 582/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.8135 - val_loss: -15.5333\n",
      "Epoch 583/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.6792 - val_loss: -15.5337\n",
      "Epoch 584/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.6615 - val_loss: -15.5340\n",
      "Epoch 585/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.7148 - val_loss: -15.5346\n",
      "Epoch 586/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.1328 - val_loss: -15.5357\n",
      "Epoch 587/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.6822 - val_loss: -15.5361\n",
      "Epoch 588/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.2047 - val_loss: -15.5371\n",
      "Epoch 589/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -43.0493 - val_loss: -15.5387\n",
      "Epoch 590/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.6183 - val_loss: -15.5404\n",
      "Epoch 591/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.0424 - val_loss: -15.5417\n",
      "Epoch 592/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.8481 - val_loss: -15.5419\n",
      "Epoch 593/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -41.7144 - val_loss: -15.5425\n",
      "Epoch 594/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.2972 - val_loss: -15.5435\n",
      "Epoch 595/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.6319 - val_loss: -15.5447\n",
      "Epoch 596/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -42.0409 - val_loss: -15.5448\n",
      "Epoch 597/1000\n",
      "121/121 [==============================] - 0s 85us/step - loss: -40.4024 - val_loss: -15.5449\n",
      "Epoch 598/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -41.0028 - val_loss: -15.5446\n",
      "Epoch 599/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.9805 - val_loss: -15.5452\n",
      "Epoch 600/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.0272 - val_loss: -15.5465\n",
      "Epoch 601/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -41.7976 - val_loss: -15.5471\n",
      "Epoch 602/1000\n",
      "121/121 [==============================] - 0s 334us/step - loss: -41.3713 - val_loss: -15.5476\n",
      "Epoch 603/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -42.4171 - val_loss: -15.5488\n",
      "Epoch 604/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -42.3923 - val_loss: -15.5495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/1000\n",
      "121/121 [==============================] - 0s 151us/step - loss: -41.0624 - val_loss: -15.5502\n",
      "Epoch 606/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.9987 - val_loss: -15.5512\n",
      "Epoch 607/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.7845 - val_loss: -15.5531\n",
      "Epoch 608/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -40.4182 - val_loss: -15.5531\n",
      "Epoch 609/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.9173 - val_loss: -15.5537\n",
      "Epoch 610/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -40.4234 - val_loss: -15.5539\n",
      "Epoch 611/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.3409 - val_loss: -15.5546\n",
      "Epoch 612/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -40.9735 - val_loss: -15.5548\n",
      "Epoch 613/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.2842 - val_loss: -15.5556\n",
      "Epoch 614/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.2930 - val_loss: -15.5559\n",
      "Epoch 615/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -41.2378 - val_loss: -15.5564\n",
      "Epoch 616/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.7420 - val_loss: -15.5577\n",
      "Epoch 617/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.7194 - val_loss: -15.5589\n",
      "Epoch 618/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -41.0282 - val_loss: -15.5589\n",
      "Epoch 619/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.2497 - val_loss: -15.5594\n",
      "Epoch 620/1000\n",
      "121/121 [==============================] - 0s 339us/step - loss: -42.2859 - val_loss: -15.5606\n",
      "Epoch 621/1000\n",
      "121/121 [==============================] - 0s 16us/step - loss: -42.5218 - val_loss: -15.5613\n",
      "Epoch 622/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8667 - val_loss: -15.5613\n",
      "Epoch 623/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.5332 - val_loss: -15.5622\n",
      "Epoch 624/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.9477 - val_loss: -15.5634\n",
      "Epoch 625/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -43.4054 - val_loss: -15.5652\n",
      "Epoch 626/1000\n",
      "121/121 [==============================] - 0s 500us/step - loss: -44.2372 - val_loss: -15.5667\n",
      "Epoch 627/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4163 - val_loss: -15.5663\n",
      "Epoch 628/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.0008 - val_loss: -15.5665\n",
      "Epoch 629/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.7284 - val_loss: -15.5664\n",
      "Epoch 630/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -41.4718 - val_loss: -15.5661\n",
      "Epoch 631/1000\n",
      "121/121 [==============================] - 0s 249us/step - loss: -41.1841 - val_loss: -15.5664\n",
      "Epoch 632/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.2377 - val_loss: -15.5674\n",
      "Epoch 633/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.9785 - val_loss: -15.5685\n",
      "Epoch 634/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8321 - val_loss: -15.5686\n",
      "Epoch 635/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -41.9575 - val_loss: -15.5692\n",
      "Epoch 636/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.3464 - val_loss: -15.5691\n",
      "Epoch 637/1000\n",
      "121/121 [==============================] - 0s 416us/step - loss: -42.3892 - val_loss: -15.5699\n",
      "Epoch 638/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -41.1258 - val_loss: -15.5702\n",
      "Epoch 639/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: -40.4844 - val_loss: -15.5701\n",
      "Epoch 640/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.4551 - val_loss: -15.5700\n",
      "Epoch 641/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.6998 - val_loss: -15.5716\n",
      "Epoch 642/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8313 - val_loss: -15.5721\n",
      "Epoch 643/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: -39.9230 - val_loss: -15.5725\n",
      "Epoch 644/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.4554 - val_loss: -15.5731\n",
      "Epoch 645/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.1833 - val_loss: -15.5733\n",
      "Epoch 646/1000\n",
      "121/121 [==============================] - 0s 168us/step - loss: -41.6403 - val_loss: -15.5740\n",
      "Epoch 647/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -42.4987 - val_loss: -15.5750\n",
      "Epoch 648/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -41.5354 - val_loss: -15.5754\n",
      "Epoch 649/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -42.8430 - val_loss: -15.5764\n",
      "Epoch 650/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.5049 - val_loss: -15.5770\n",
      "Epoch 651/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.1346 - val_loss: -15.5776\n",
      "Epoch 652/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -43.1602 - val_loss: -15.5788\n",
      "Epoch 653/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.1688 - val_loss: -15.5790\n",
      "Epoch 654/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.1896 - val_loss: -15.5786\n",
      "Epoch 655/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.6292 - val_loss: -15.5800\n",
      "Epoch 656/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.0306 - val_loss: -15.5807\n",
      "Epoch 657/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -41.4451 - val_loss: -15.5811\n",
      "Epoch 658/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -40.5338 - val_loss: -15.5813\n",
      "Epoch 659/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.2785 - val_loss: -15.5812\n",
      "Epoch 660/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -43.8488 - val_loss: -15.5826\n",
      "Epoch 661/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4160 - val_loss: -15.5825\n",
      "Epoch 662/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -40.5433 - val_loss: -15.5826\n",
      "Epoch 663/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.6932 - val_loss: -15.5835\n",
      "Epoch 664/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4556 - val_loss: -15.5839\n",
      "Epoch 665/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -41.0755 - val_loss: -15.5838\n",
      "Epoch 666/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -41.6357 - val_loss: -15.5843\n",
      "Epoch 667/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -41.2224 - val_loss: -15.5842\n",
      "Epoch 668/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.3739 - val_loss: -15.5848\n",
      "Epoch 669/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.8374 - val_loss: -15.5852\n",
      "Epoch 670/1000\n",
      "121/121 [==============================] - 0s 416us/step - loss: -41.1387 - val_loss: -15.5855\n",
      "Epoch 671/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: -40.9856 - val_loss: -15.5855\n",
      "Epoch 672/1000\n",
      "121/121 [==============================] - 0s 183us/step - loss: -41.9205 - val_loss: -15.5861\n",
      "Epoch 673/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8782 - val_loss: -15.5861\n",
      "Epoch 674/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -42.5986 - val_loss: -15.5873\n",
      "Epoch 675/1000\n",
      "121/121 [==============================] - 0s 129us/step - loss: -40.9424 - val_loss: -15.5880\n",
      "Epoch 676/1000\n",
      "121/121 [==============================] - 0s 0us/step - loss: -41.0332 - val_loss: -15.5880\n",
      "Epoch 677/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.6508 - val_loss: -15.5891\n",
      "Epoch 678/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -41.5471 - val_loss: -15.5899\n",
      "Epoch 679/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -41.9138 - val_loss: -15.5906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.2908 - val_loss: -15.5917\n",
      "Epoch 681/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -40.3459 - val_loss: -15.5914\n",
      "Epoch 682/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -40.7624 - val_loss: -15.5911\n",
      "Epoch 683/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -40.7192 - val_loss: -15.5910\n",
      "Epoch 684/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.6578 - val_loss: -15.5911\n",
      "Epoch 685/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.1507 - val_loss: -15.5912\n",
      "Epoch 686/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -41.2630 - val_loss: -15.5914\n",
      "Epoch 687/1000\n",
      "121/121 [==============================] - 0s 399us/step - loss: -41.4791 - val_loss: -15.5916\n",
      "Epoch 688/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.6628 - val_loss: -15.5932\n",
      "Epoch 689/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -44.1679 - val_loss: -15.5949\n",
      "Epoch 690/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.5539 - val_loss: -15.5948\n",
      "Epoch 691/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.7473 - val_loss: -15.5950\n",
      "Epoch 692/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.5525 - val_loss: -15.5948\n",
      "Epoch 693/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.6419 - val_loss: -15.5950\n",
      "Epoch 694/1000\n",
      "121/121 [==============================] - 0s 333us/step - loss: -41.0287 - val_loss: -15.5951\n",
      "Epoch 695/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.3685 - val_loss: -15.5951\n",
      "Epoch 696/1000\n",
      "121/121 [==============================] - 0s 416us/step - loss: -41.0837 - val_loss: -15.5952\n",
      "Epoch 697/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.2225 - val_loss: -15.5964\n",
      "Epoch 698/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -42.5292 - val_loss: -15.5972\n",
      "Epoch 699/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.8939 - val_loss: -15.5971\n",
      "Epoch 700/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: -42.1233 - val_loss: -15.5978\n",
      "Epoch 701/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.2314 - val_loss: -15.5982\n",
      "Epoch 702/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.0609 - val_loss: -15.5980\n",
      "Epoch 703/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.6961 - val_loss: -15.5978\n",
      "Epoch 704/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.8711 - val_loss: -15.5984\n",
      "Epoch 705/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -40.8623 - val_loss: -15.5984\n",
      "Epoch 706/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.6023 - val_loss: -15.5985\n",
      "Epoch 707/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.4108 - val_loss: -15.5997\n",
      "Epoch 708/1000\n",
      "121/121 [==============================] - 0s 66us/step - loss: -42.5954 - val_loss: -15.6002\n",
      "Epoch 709/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.4525 - val_loss: -15.6002\n",
      "Epoch 710/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.5454 - val_loss: -15.5997\n",
      "Epoch 711/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -41.0863 - val_loss: -15.5997\n",
      "Epoch 712/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.3629 - val_loss: -15.6002\n",
      "Epoch 713/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -41.8265 - val_loss: -15.6010\n",
      "Epoch 714/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -40.7182 - val_loss: -15.6011\n",
      "Epoch 715/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -42.5451 - val_loss: -15.6014\n",
      "Epoch 716/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -42.2526 - val_loss: -15.6017\n",
      "Epoch 717/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -41.9743 - val_loss: -15.6024\n",
      "Epoch 718/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -41.9227 - val_loss: -15.6024\n",
      "Epoch 719/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4822 - val_loss: -15.6022\n",
      "Epoch 720/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.6114 - val_loss: -15.6020\n",
      "Epoch 721/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.8799 - val_loss: -15.6030\n",
      "Epoch 722/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3096 - val_loss: -15.6027\n",
      "Epoch 723/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -40.8826 - val_loss: -15.6029\n",
      "Epoch 724/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.3085 - val_loss: -15.6028\n",
      "Epoch 725/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.8058 - val_loss: -15.6043\n",
      "Epoch 726/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.2023 - val_loss: -15.6045\n",
      "Epoch 727/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.6420 - val_loss: -15.6044\n",
      "Epoch 728/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.0843 - val_loss: -15.6045\n",
      "Epoch 729/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.2872 - val_loss: -15.6047\n",
      "Epoch 730/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -44.2550 - val_loss: -15.6067\n",
      "Epoch 731/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.7731 - val_loss: -15.6062\n",
      "Epoch 732/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8020 - val_loss: -15.6061\n",
      "Epoch 733/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -41.7871 - val_loss: -15.6060\n",
      "Epoch 734/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.0290 - val_loss: -15.6059\n",
      "Epoch 735/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -40.9102 - val_loss: -15.6059\n",
      "Epoch 736/1000\n",
      "121/121 [==============================] - 0s 67us/step - loss: -40.5079 - val_loss: -15.6057\n",
      "Epoch 737/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3149 - val_loss: -15.6055\n",
      "Epoch 738/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.7396 - val_loss: -15.6070\n",
      "Epoch 739/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.3336 - val_loss: -15.6066\n",
      "Epoch 740/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.8503 - val_loss: -15.6077\n",
      "Epoch 741/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -40.8949 - val_loss: -15.6075\n",
      "Epoch 742/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.8579 - val_loss: -15.6077\n",
      "Epoch 743/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.0590 - val_loss: -15.6085\n",
      "Epoch 744/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.0419 - val_loss: -15.6085\n",
      "Epoch 745/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.5559 - val_loss: -15.6094\n",
      "Epoch 746/1000\n",
      "121/121 [==============================] - 0s 267us/step - loss: -40.5545 - val_loss: -15.6088\n",
      "Epoch 747/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -40.9742 - val_loss: -15.6089\n",
      "Epoch 748/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -40.9453 - val_loss: -15.6085\n",
      "Epoch 749/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -40.9839 - val_loss: -15.6083\n",
      "Epoch 750/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.3652 - val_loss: -15.6087\n",
      "Epoch 751/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.7477 - val_loss: -15.6100\n",
      "Epoch 752/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.4307 - val_loss: -15.6101\n",
      "Epoch 753/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.3057 - val_loss: -15.6116\n",
      "Epoch 754/1000\n",
      "121/121 [==============================] - 0s 100us/step - loss: -40.6076 - val_loss: -15.6114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/1000\n",
      "121/121 [==============================] - 0s 167us/step - loss: -41.9264 - val_loss: -15.6113\n",
      "Epoch 756/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.5549 - val_loss: -15.6112\n",
      "Epoch 757/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.8083 - val_loss: -15.6109\n",
      "Epoch 758/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.5212 - val_loss: -15.6121\n",
      "Epoch 759/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -42.6578 - val_loss: -15.6130\n",
      "Epoch 760/1000\n",
      "121/121 [==============================] - 0s 17us/step - loss: -43.1863 - val_loss: -15.6141\n",
      "Epoch 761/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.7810 - val_loss: -15.6134\n",
      "Epoch 762/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -41.8403 - val_loss: -15.6138\n",
      "Epoch 763/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -44.2634 - val_loss: -15.6155\n",
      "Epoch 764/1000\n",
      "121/121 [==============================] - 0s 150us/step - loss: -40.5041 - val_loss: -15.6142\n",
      "Epoch 765/1000\n",
      "121/121 [==============================] - 0s 250us/step - loss: -42.0093 - val_loss: -15.6139\n",
      "Epoch 766/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.4108 - val_loss: -15.6146\n",
      "Epoch 767/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.0239 - val_loss: -15.6139\n",
      "Epoch 768/1000\n",
      "121/121 [==============================] - 0s 84us/step - loss: -40.5126 - val_loss: -15.6134\n",
      "Epoch 769/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -40.9330 - val_loss: -15.6128\n",
      "Epoch 770/1000\n",
      "121/121 [==============================] - 0s 166us/step - loss: -42.6387 - val_loss: -15.6137\n",
      "Epoch 771/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -41.9953 - val_loss: -15.6133\n",
      "Epoch 772/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -43.0418 - val_loss: -15.6138\n",
      "Epoch 773/1000\n",
      "121/121 [==============================] - 0s 83us/step - loss: -42.3705 - val_loss: -15.6144\n",
      "Epoch 00773: early stopping\n",
      "                        Model       MSE  Size  Number        SE  Performance\n",
      "99_99  PPFD_Avg+VPD+VWC+Shrub  0.012127    99      99  0.010978            0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params['N']=int(y.shape[0]/30)\n",
    "params['Memory'] = (math.floor(100/params['proc'])- 5/params['proc']) * .01\n",
    "Y_hat=[]\n",
    "y_true=[]\n",
    "X_true=[]\n",
    "index=[]\n",
    "ones=[]\n",
    "prog2.value=0\n",
    "if MP == False:\n",
    "    for k in range(params['K']):\n",
    "        Time2 = time.time()\n",
    "        results = Dense.Bootstrap(k,params,X,y)\n",
    "        Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "        y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "        X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "        ones.append(results[3])\n",
    "        prog2.value=(k+1)/params['K']*100\n",
    "        print(time.time()-Time2)\n",
    "else:\n",
    "    pool = Pool(processes=processes,maxtasksperchild=75)\n",
    "    for k,results in enumerate(pool.imap(partial(Dense.Bootstrap,params=params,X=X,y=y),\n",
    "                                         range(0,params['K']))):\n",
    "        Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "        y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "        X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "        ones.append(results[3])\n",
    "        prog2.value=(k+1)/params['K']*100\n",
    "    pool.close()\n",
    "Y_hat = np.squeeze(np.asanyarray(Y_hat))\n",
    "y_true = np.squeeze(np.asanyarray(y_true))\n",
    "X_true = np.asanyarray(X_true)\n",
    "ones = np.asanyarray(ones)\n",
    "params['Memory'] = .95mse,se = Dense.Sort_outputs(k,params,Y_hat,y_true,X_true,ones)\n",
    "    \n",
    "Level = Stats(mse,se,j,i,params)\n",
    "Level.to_csv(params['Dpath']+Name+'.csv')\n",
    "\n",
    "\n",
    "print(Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.05049088 -1.70307724 -1.57942366 -1.37920098 -1.34082142 -1.29817202\n",
      " -1.25915649 -1.16175916 -1.13263573 -1.00571106 -1.00546125 -1.00530066\n",
      " -0.96262693 -0.92438254 -0.88731533 -0.88195375 -0.88121361 -0.84990671\n",
      " -0.84113089 -0.82105317 -0.77941022 -0.73628584 -0.71609678 -0.71389443\n",
      " -0.67974229 -0.64355934 -0.63726896 -0.62916789 -0.62911801 -0.61945251\n",
      " -0.61064209 -0.58854058 -0.58317715 -0.51884264 -0.5138074  -0.49094798\n",
      " -0.47391205 -0.41252118 -0.37061004 -0.32879919 -0.320301   -0.29642946\n",
      " -0.28675162 -0.26320618 -0.21803478 -0.21367761 -0.21189709 -0.20535009\n",
      " -0.19461813 -0.13131386 -0.11156801 -0.05621621 -0.03222702 -0.01083632\n",
      "  0.0066908   0.08365594  0.08726808  0.10341208  0.10995812  0.14112623\n",
      "  0.14995285  0.18798269  0.18929876  0.2135496   0.21691326  0.26138948\n",
      "  0.26175181  0.26979142  0.27315616  0.31238947  0.32762416  0.34843636\n",
      "  0.35021835  0.35113825  0.39105801  0.40182803  0.44023556  0.47565597\n",
      "  0.4788692   0.50384729  0.55830336  0.60705635  0.69672786  0.80073143\n",
      "  0.80193937  0.86448037  0.9888894   1.06647367  1.07174104  1.08830301\n",
      "  1.15258143  1.23294008  1.3106981   1.32711101  1.38561324  1.65076578\n",
      "  1.68141024  1.79602285  2.02066359  3.58976931  4.56959809]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depth = 11\n",
    "Time = time.time()\n",
    "FirstRun == False\n",
    "kwit = 0\n",
    "if __name__ == '__main__':\n",
    "    for target in ['fco2','fch4']:\n",
    "        XVarriables=ModSelect(Scope,Site)\n",
    "        if target == 'fch4' and Site == 'FishIsland':\n",
    "            XVarriables.append('fco2')\n",
    "        if FirstRun == True:\n",
    "            start=1\n",
    "            stop = len(XVarriables)\n",
    "            if depth < stop:\n",
    "                stop = depth\n",
    "            stop += 2\n",
    "            try:shutil.rmtree(cwd+'/'+Site+'/'+target+'/')\n",
    "            except:pass\n",
    "            os.mkdir(cwd+'/'+Site+'/'+target+'/')\n",
    "        else:\n",
    "            params = Dense.Params(Scope,target,MP)\n",
    "            params['Dpath'] = cwd+'/'+Site+'/'\n",
    "            Records = pd.read_csv(cwd+'/'+Site+'/'+target+'_Runs.csv',delimiter = ',',header = 0,index_col=[0])\n",
    "            start = 2#Records['Size'].max()+1\n",
    "            Level = Records.loc[Records['Size']==start-1]\n",
    "            Min = Level.loc[Level['MSE']==Level['MSE'].min()]\n",
    "            Sv = (((Level['SE']**2+Min['SE'].values[0]**2)/2)**.5)\n",
    "            Level['T']=(Level['MSE']-Min['MSE'].values[0])/(Sv*(2/params['K'])**.5)\n",
    "            Factors = Level.loc[Level['T']<=stats.t.ppf(1-alpha,params['K']),'Model'].values\n",
    "            Level.loc[Level['T']<=stats.t.ppf(1-alpha,params['K']),'Performance']=1\n",
    "            \n",
    "            stop = len(XVarriables)\n",
    "            if start >2:\n",
    "                Last = Records.loc[Records['Size']==start-2].sort_values('MSE').reset_index()\n",
    "                Rec = Last.loc[Last['MSE']==Last['MSE'].min()]\n",
    "                Sv = (((Level['SE']**2+Rec['SE'].values[0]**2)/2)**.5)\n",
    "                Level['T2']=(Level['MSE']-Rec['MSE'].values[0])/(Sv*(2/params['K'])**.5)\n",
    "\n",
    "                Level.loc[Level['T2']<=-stats.t.ppf(1-alpha,params['K']),'Performance']+=1\n",
    "                Factors = Level.loc[Level['Performance']>=2,'Model'].values\n",
    "#             print(Records)\n",
    "                 \n",
    "        tar.value=target\n",
    "        prog1 = FloatProgress(min=start, max=stop,description='Running:')\n",
    "        prog2 = FloatProgress(min=0, max=100,description='Bootstrapping:')\n",
    "        MdLs = HTML(\n",
    "            value=\" \",\n",
    "            placeholder='Models: ',\n",
    "            description='Models: ',\n",
    "        )\n",
    "        MdL = HTML(\n",
    "            value=\" \",\n",
    "            placeholder='Testing: ',\n",
    "            description='Testing: ',\n",
    "        )\n",
    "        Display (tar,prog1,prog2,MdLs,MdL)\n",
    "\n",
    "        for j in range(start,stop):\n",
    "            if j == 1 and Site == 'Illisarvik' and target == 'fco2': Inputs = [['PPFD_Avg']]#(Combos(['PPFD_Avg'],j))\n",
    "            elif j == 1: Inputs = (Combos(XVarriables,j))\n",
    "#             print(Inputs)\n",
    "#             if j == 1: Inputs = (Combos(XVarriables,j))\n",
    "            else: Inputs = (Combos(XVarriables,j,Factors))\n",
    "#             print(Inputs,XVarriables,j,Factors)\n",
    "            MdLs.value=str(len(Inputs))\n",
    "            i = 0\n",
    "            procede = True\n",
    "            for Input in Inputs:\n",
    "#                 print(Input,start,stop)\n",
    "                if FirstRun == False:\n",
    "#                     print(Records.isin({'Size':[j]}).any().any())\n",
    "                    if Records.loc[Records['Size']==j].isin({'Number':[i]}).any().any()==True:\n",
    "                        procede = False\n",
    "                    else:\n",
    "                        procede = True\n",
    "                if procede == True:\n",
    "                    params = Dense.Params(Scope,target,MP)\n",
    "                    params['Dpath'] = cwd+'/'+Site+'/'\n",
    "                    params['Spath'] = params['Dpath']+'/'+target+'/'+str(j)+'_'+str(i)+'/'\n",
    "                    try:os.mkdir(params['Spath'])\n",
    "                    except:pass\n",
    "                    params['Sname'] = 'Y_'\n",
    "                    params['Inputs'] = Input\n",
    "                    MdL.value='#'+str(i)+' '+str(params['Inputs'])\n",
    "                    Display (tar,prog1,prog2,MdLs,MdL)\n",
    "#                     try:\n",
    "#                         print(Level.sort_values('MSE'))\n",
    "#                     except:\n",
    "#                         pass\n",
    "                    print('Runtime: ',time.time()-Time)\n",
    "                    params['Model'] = '+'.join(params['Inputs'])\n",
    "                    RST = RSTF.ReadStandardTimeFill(params,'ECData.csv')#,resample='2H')\n",
    "                    if target == 'ER':\n",
    "                        RST.Master = RST.Master.loc[RST.Master['fco2']>0]\n",
    "                    RST.Scale(params['target'],params['Inputs']) \n",
    "                    y = RST.y*1.0\n",
    "                    X = RST.X*1.0\n",
    "                    params['N']=int(y.shape[0]/30)\n",
    "                    params['Memory'] = (math.floor(100/params['proc'])- 5/params['proc']) * .01\n",
    "                    Y_hat=[]\n",
    "                    y_true=[]\n",
    "                    X_true=[]\n",
    "                    index=[]\n",
    "                    ones=[]\n",
    "                    prog2.value=0\n",
    "                    pool = Pool(processes=processes,maxtasksperchild=75)\n",
    "                    for k,results in enumerate(pool.imap(partial(Dense.Bootstrap,params=params,X=X,y=y),range(params['K']))):\n",
    "                        Y_hat.append(RST.YScaled.inverse_transform(results[0]))\n",
    "                        y_true.append(RST.YScaled.inverse_transform(results[1]))\n",
    "                        X_true.append(RST.XScaled.inverse_transform(results[2]))\n",
    "                        ones.append(results[3])\n",
    "                        prog2.value=(k+1)/params['K']*100\n",
    "                    pool.close()\n",
    "                    Y_hat = np.squeeze(np.asanyarray(Y_hat))\n",
    "                    y_true = np.squeeze(np.asanyarray(y_true))\n",
    "                    X_true = np.asanyarray(X_true)\n",
    "                    ones = np.asanyarray(ones)\n",
    "                    params['Memory'] = .95\n",
    "#                     if MP == False:\n",
    "#                         for k in range(1):\n",
    "#                              mse,se = Dense.Sort_outputs(k,params,Y_hat,y_true,X_true,ones)\n",
    "#                     else:\n",
    "                    pool = Pool(processes=1,maxtasksperchild=75)\n",
    "                    for k,results in enumerate(pool.imap(partial(Dense.Sort_outputs,params=params,\n",
    "                     Y_hat=Y_hat,y_true=y_true,X_true=X_true,ones=ones),range(1))):\n",
    "                         mse,se = results\n",
    "                    pool.close()\n",
    "                    if i == 0 and FirstRun == True:Level = Stats(mse,se,j,i,params)\n",
    "                    else:\n",
    "                        Level = Level.loc[Level['Size']==j]\n",
    "                        Level = Level.append(Stats(mse,se,j,i,params))\n",
    "                i += 1\n",
    "                prog1.value=j+i/len(Inputs)\n",
    "            Min = Level.loc[Level['MSE']==Level['MSE'].min()]          \n",
    "            Level.loc[Level['MSE']==Min['MSE'].values[0],'Performance']=1\n",
    "            Level.loc[Level['MSE']<=Min['MSE'].values[0]+Min['SE'].values[0],'Performance']+=1\n",
    "            Factors = Level.loc[Level['Performance']>=2,'Model'].values\n",
    "            print(Factors)\n",
    "#             if j == 1 and Site == 'Illisarvik' and target == 'fco2':\n",
    "#                 Factors = ['PPFD_Avg']\n",
    "            print(Factors,i,j)\n",
    "            if j == 1:\n",
    "                Records = Level\n",
    "            else:\n",
    "                Records = Records.append(Level)\n",
    "                \n",
    "#             kwt.value = str(kwit)\n",
    "            Records = Records.reset_index(drop=True)\n",
    "            Records.drop(Records.columns[Records.columns.str.contains('Unnamed',case = False)],axis = 1)\n",
    "            if Scope == 'Full':\n",
    "                Records.to_csv(params['Dpath']+'/'+target+'_Runs.csv')\n",
    "            else:\n",
    "                Records.to_csv(params['Dpath']+'/'+target+'_Runs2.csv')\n",
    "#             print(Records)\n",
    "            if Level['Performance'].max()<2 and j>1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Level.loc[Level['MSE']==Min['MSE'].values[0],'Performance']=1\n",
    "# Level.loc[Level['MSE']<=Min['MSE'].values[0]+Min['SE'].values[0],'Performance']+=1\n",
    "# print(Min['MSE'].values[0]+Min['SE'].values[0])\n",
    "# print(Min)\n",
    "# print(Level)\n",
    "print(Records)\n",
    "Records.to_csv(params['Dpath']+'/'+target+'_Runs.csv')\n",
    "\n",
    "# print(Factors,start,stop,i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(params)\n",
    "\n",
    "# Level = Stats(mse,se,j,i,params)\n",
    "# Level.to_csv(params['Dpath']+target+'_Final_Runs.csv')\n",
    "\n",
    "# plt.figure()\n",
    "# print(RST.Master\n",
    "#      )\n",
    "\n",
    "# pool = Pool(processes=1,maxtasksperchild=75)\n",
    "# for k,results in enumerate(pool.imap(partial(Dense.Sort_outputs,params=params,\n",
    "#  Y_hat=Y_hat,y_true=y_true,X_true=X_true,ones=ones),range(1))):\n",
    "#      mse,se = results\n",
    "# pool.close()\n",
    "\n",
    "# plt.scatter(Y_hat,y_true)\n",
    "# print(metrics.mean_squared_error(y_true,Y_hat))\n",
    "# print(metrics.r2_score(y_true,Y_hat))\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(Y_hat)\n",
    "# plt.plot(y_true)\n",
    "\n",
    "# print(Y_hat.shape,y_true.shape)\n",
    "print(Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "\n",
    "# print(Data[params['target']])\n",
    "\n",
    "for ip in params['Inputs']:\n",
    "    RST.Data[ip] = RST.Data[ip].mean()\n",
    "\n",
    "Key = 'Sedge'\n",
    "KeyRange = {'min':0,'max':1}\n",
    "RST.Data[Key] = np.linspace(KeyRange['min'],KeyRange['max'],RST.Data[Key].shape[0])\n",
    "RST.Scale(params['target'],params['Inputs'],ScalePath=params['Spath'],Project=Project)\n",
    "    \n",
    "# print(Data[params['target']])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if Fill == True:\n",
    "        X = RST.X_fill\n",
    "    else:\n",
    "        X = RST.X\n",
    "    params['Sname']='Y_'\n",
    "    Y_fill = []\n",
    "    MSE = []\n",
    "#     for i in range(params['K']):\n",
    "        \n",
    "        \n",
    "        \n",
    "    if MP == False:\n",
    "        for k in range(params['K']):\n",
    "            Y = Dense.Load_Model(k,X,params)\n",
    "            Y = RST.YScaled.inverse_transform(Y)\n",
    "            if Fill == False:\n",
    "                mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "                MSE.append(mse)\n",
    "            Y_fill.append(Y)\n",
    "    else:\n",
    "        pool = Pool(processes=1,maxtasksperchild=75)\n",
    "        for k,results in enumerate(pool.imap(partial(Dense.Load_Model,X=X,params=params),range(params['K']))):\n",
    "            Y = results\n",
    "            Yold = Y+0\n",
    "            Y = RST.YScaled.inverse_transform(Y)\n",
    "#             plt.figure()\n",
    "#             plt.scatter(Y,Yold)\n",
    "#             plt.xlabel('Sca;e')\n",
    "#             print(RST.YScaled)\n",
    "            if Fill == False:\n",
    "                mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "                MSE.append(mse)\n",
    "            Y_fill.append(Y)                       \n",
    "        pool.close()\n",
    "#         params['iteration']=i\n",
    "\n",
    "#         Y = Dense.Load_Model(i,X,params)\n",
    "#         Model = Dense.Load_Weights(Empty_Mod,params) \n",
    "#         Y = RST.YScaled.inverse_transform(Y)#Model.predict(X).reshape(-1,1))\n",
    "#         if Fill == False:\n",
    "#             mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "#             MSE.append(mse)\n",
    "#         Y_fill.append(Y)\n",
    "    Y_fill = np.asanyarray(Y_fill).mean(axis=-1)\n",
    "    Y_fill_bar = Y_fill.mean(axis=0)\n",
    "    if Fill == False:\n",
    "        MSE = np.asanyarray(MSE)\n",
    "        CI = stats.t.ppf(1-0.025,k)*MSE.std()/(k)**.5\n",
    "        print(CI)\n",
    "\n",
    "    YStandard = joblib.load(params['Spath']+\"YVar_scaler.save\") \n",
    "    params['Sname']='Var'\n",
    "#     params['iteration']=1\n",
    "    params['Loss']='Boot_Loss'\n",
    "#     YVar = Dense.Load_Model(1,X,params)\n",
    "#     Model = Dense.Load_Weights(Empty_Mod,params)        \n",
    "    if MP == False:\n",
    "        for k in range(1,2):\n",
    "            YVar = Dense.Load_Model(k,X,params)\n",
    "            YVar = RST.YScaled.inverse_transform(YVar)\n",
    "#             if Fill == False:\n",
    "#                 mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "#                 MSE.append(mse)\n",
    "#             Y_fill.append(Y)\n",
    "    else:\n",
    "        pool = Pool(processes=1,maxtasksperchild=75)\n",
    "        for k,results in enumerate(pool.imap(partial(Dense.Load_Model,X=X,params=params),range(1,2))):\n",
    "            YVar = results\n",
    "            YVar = RST.YScaled.inverse_transform(YVar)\n",
    "#             if Fill == False:\n",
    "#                 mse = (metrics.mean_squared_error(RST.y,Y))\n",
    "#                 MSE.append(mse)\n",
    "#             Y_fill.append(Y)                       \n",
    "        pool.close()\n",
    "#     YVar=YStandard.inverse_transform(YVar)#Model.predict(X).reshape(-1,1))\n",
    "    X_back = np.squeeze(RST.XScaled.inverse_transform(X))\n",
    "\n",
    "\n",
    "Data = pd.DataFrame(data=X_back,columns=params['Inputs'])\n",
    "Data[target] = np.squeeze(Y_fill_bar)\n",
    "Data['True'] = RST.Ytru#.YScaled.inverse_transform(RST.y)\n",
    "Data['SE'] = 1/(params['K']-1)*((Y_fill-Y_fill_bar)**2).sum(axis=0)\n",
    "Data['Var'] = np.squeeze(YVar)\n",
    "Data['CI']=stats.t.ppf(1-0.025,params['K'])*(Data['SE'])**.5\n",
    "Data['PI']=stats.t.ppf(1-0.025,params['K'])*((Data['Var']+Data['SE'])**.5) #the accuracy of our estimate with respect to the observed output\n",
    "\n",
    "# print(Data['CI'].mean())\n",
    "print(params['Inputs'])\n",
    "print('Prediction mean: ',Data[target].mean())\n",
    "print('Target mean: ',Data['True'].mean())\n",
    "Data['Fill'] = Data['True'].fillna(Data[target])\n",
    "print('GapFilled mean: ',Data['Fill'].mean())\n",
    "\n",
    "Data.loc[np.isnan(Data['PI'])==True,'PI']=Data['CI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "Data = Data.sort_values(by=Key)\n",
    "# Data.index = Data[Key]\n",
    "\n",
    "Data = Data[np.isfinite(Data['True'])]\n",
    "\n",
    "plt.scatter(RST.Master[Key],RST.Master[target],edgecolor='black',facecolor='white')\n",
    "plt.plot(Data[Key],Data[target],\n",
    "         label= params['target']+' Model\\nr^2: '+str(np.round(metrics.r2_score(Data['True'],\n",
    "                                                                   Data[params['target']])**2,3)))\n",
    "# plt.plot(Data.index,Data['Var'],label= params['target']+\n",
    "# ' Model\\nRMSE: '+str(np.round(metrics.mean_squared_error(Data['True'],\n",
    "#                                                                    Data[params['target']])**2,3)))\n",
    "\n",
    "\n",
    "plt.fill_between(Data[Key], Data[target]-Data['PI'], \n",
    "                 Data[target]+Data['PI'],  color = 'green', alpha = 0.4, \n",
    "                 label = '95% PI')\n",
    "plt.fill_between(Data[Key], Data[target]-Data['CI'], \n",
    "                 Data[target]+Data['CI'],  color = 'red', alpha = 0.4, \n",
    "                 label = '95% CI')\n",
    "plt.legend()\n",
    "# print(RST.Master)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# plt.plot(Data[Key], Data['Var'])\n",
    "\n",
    "plt.scatter(Data[target],Data['True'])\n",
    "\n",
    "# print(Data['SE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
